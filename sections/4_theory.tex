\section{Statistical and Information Theoretic Foundations of Algorithmic Reasoning}
\label{sec:theory}
% Following \cite{blackwell1953equivalent}, we prove that $Arm 1 \simeq Arm 2 < Arm 3$ leveraging a similar breakdown framework as our experiments. We utilize information theory and statistical decision theory to sidestep representing the ambiguity of natural language and differences between NL and Code in a mathematical framework. \yu{Using the intuitions we gain in our hypothesis experiments in section~\ref{sec:exp_similarity}}, we prove that Arm 2 is at least as good as Arm 1, and that Arm 3 is always better than Arm 2. 

Following \citet{blackwell1953equivalent}, we formalize the comparison between our arms by separating (i) the \emph{information structure} available to the agent from (ii) the \emph{decision rule} used to map that information to an answer. Concretely, each arm induces an \emph{experiment} (a channel from task instances to traces) together with a restricted class of \emph{executors} (decision rules) that operate on the trace. This separation clarifies which comparisons are information-theoretic (Blackwell-style) versus computational (executor-class–dependent).

\subsection{Preliminaries}
\paragraph{State, experiment, and decision rule.}
Let $X \sim p(x)$ denote a task instance (problem statement plus inputs) drawn from a test distribution $p$. Each instance has a ground-truth output $Y^*(X) \in \mathcal{Y}$. We evaluate 0--1 loss
\[
\ell(y, x) := \mathbf{1}\{y \neq Y^*(x)\} \in \{0,1\}.
\]
An \emph{experiment} (information structure) is a conditional distribution over traces $Z \in \mathcal{Z}$ given the instance,
\[
E : x \mapsto p_E(z \mid x).
\]
A (possibly randomized) \emph{decision rule} or \emph{executor} is a conditional distribution over outputs given the instance and trace,
\[
\rho : (x,z) \mapsto \rho(y \mid x, z).
\]
Given $(E,\rho)$, the induced output distribution is
\[
P_{\rho,E}(Y=y \mid X=x) \;=\; \int \rho(y \mid x, z)\, p_E(z \mid x)\, dz.
\]

\paragraph{Arm-specific experiments and executors.}
Arm~1 (NL) corresponds to the experiment $E_{\mathrm{NL}}$ with trace $Z_{\mathrm{NL}}$ generated by $p_{\mathrm{NL}}(z_{\mathrm{NL}} \mid x)$ and executed by an NL executor $\rho_{\mathrm{NL}}(y \mid x, z_{\mathrm{NL}})$.
Arm~2 (Code) corresponds to the experiment $E_{\mathrm{Code}}$ with trace $Z_{\mathrm{C}}$ generated by $p_{\mathrm{Code}}(z_{\mathrm{C}} \mid x)$ and executed by a simulator executor $\rho_{\mathrm{Sim}}(y \mid x, z_{\mathrm{C}})$.

Our empirical results in Section~\ref{sec:exp_similarity} suggest that NL traces can be approximately obtained by post-processing (garbling) code traces. In Blackwell’s framework, a \emph{garbling} is a state-independent Markov kernel applied to the signal. Concretely, we posit that there exists a (possibly stochastic) translator
\[
T : \mathcal{Z}_{\mathrm{C}} \to \Delta(\mathcal{Z}_{\mathrm{NL}}), 
\qquad z_{\mathrm{NL}} \sim T(\cdot \mid z_{\mathrm{C}}),
\]
such that the \emph{translated} NL experiment induced by $E_{\mathrm{Code}}$ satisfies
\[
p_{\mathrm{translated}}(z_{\mathrm{NL}} \mid x)
:= \int T(z_{\mathrm{NL}} \mid z_{\mathrm{C}})\, p_{\mathrm{Code}}(z_{\mathrm{C}} \mid x)\, dz_{\mathrm{C}}.
\]
Under Assumptions~\ref{assump1}--\ref{assump2}, this translated NL experiment is close (in average conditional TV distance) to the native NL experiment $E_{\mathrm{NL}}$.

\paragraph{Composing translation with execution.}
Given a translator $T(z_{\mathrm{NL}} \mid z_{\mathrm{C}})$ and any NL executor $\rho_{\mathrm{NL}}(y \mid x, z_{\mathrm{NL}})$, define the induced code-side executor that (i) samples a translated NL trace and (ii) applies the same NL executor:
\[
\rho_{\mathrm{Sim}}(y \mid x, z_{\mathrm{C}})
:= \int \rho_{\mathrm{NL}}(y \mid x, z_{\mathrm{NL}})\, T(z_{\mathrm{NL}} \mid z_{\mathrm{C}})\, dz_{\mathrm{NL}}.
\]
This definition is purely a change of decision rule: the underlying experiment remains $E_{\mathrm{Code}}$.


% \begin{align*}
%     & \mathrm{P}(Y \mid X = x) := \int T(z \mid z_{\mathrm{Code}}) \, p_{\mathrm{Code}}(z_{\mathrm{Code}} \mid x) \, \mathrm{d}z_{\mathrm{Code}}
% \end{align*}
% In Arm~1 and Arm~2, each arm corresponds to an intermediate representation $Z$ (e.g. CoT) produced by channel $p(z \mid x)$ (e.g. LLM), and then choosing an output $Y$ via a randomized decision rule $\delta(y \mid x, z)$ (i.e. LLM test-time reasoning). 
We compare arms via a representation-constrained Bayes risk, i.e., Bayes risk optimized over a restricted executor class. For an experiment $E$ with trace $Z \sim p_E(\cdot \mid X)$, define
\[
R^*(E) \;:=\; \inf_{\rho \in \mathcal{H}} \; \mathbb{E}\!\left[\mathbf{1}\{\hat Y \neq Y^*(X)\}\right],
\qquad \hat Y \sim \rho(\cdot \mid X, Z).
\]
When $E=E_{\mathrm{NL}}$ we write $R^*(E_{\mathrm{NL}})$, and when $E=E_{\mathrm{Code}}$ we write $R^*(E_{\mathrm{Code}})$. Our goal is to show that
\[
R^*(E_{\mathrm{Code}}) \;\le\; R^*(E_{\mathrm{NL}}) + O(\varepsilon).
\]


\textbf{Assumption 1.}
\label{assump1}
We assume there exists a (near Bayes optimal) translator $T$ mapping code to natural language reasoning $Z_{\mathrm{Code}} \to \hat{Z}_{\mathrm{NL}}$ independent of $X$.

\textbf{Assumption 2.}
\label{assump2}
We assume that the original NL reasoning chain of thought is close to the translated NL on average. Let $p_{\mathrm{NL}}$ be the Arm~1 channel and $p_{\mathrm{translated}}(\cdot \mid x)$ be the translated NL channel. Assume an average conditional TV bound:
\[
\mathbb{E}_{X \sim p} \bigl[
d_{\mathrm{TV}}\bigl(p_{\mathrm{NL}}(\cdot \mid X), \, p_{\mathrm{translated}}(\cdot \mid X)\bigr)
\bigr] \leq \varepsilon,
\]
where
\[
d_{\mathrm{TV}}(P, Q) = \sup_{B} |P(B) - Q(B)|.
\]
In other words, averaged over task instances, the NL trace produced by Arm~1 is close in distribution to the NL traces obtained by translating the code trace (Arm~2) using the translator $T$. We empirically verify this in experiment 2. 

\begin{proof}
We apply Blackwell’s simulation idea at the level of experiments: code traces can be post-processed into translated NL traces via the state-independent kernel $T$. We then relate performance under the native NL experiment to performance under the translated experiment using a total-variation continuity bound.

\textbf{Step 1 (Simulation via composed executor).}
Fix any NL executor $\rho_{\mathrm{NL}}(y \mid x, z_{\mathrm{NL}})$. Define $\rho_{\mathrm{Sim}}$ from $\rho_{\mathrm{NL}}$ and $T$ as
\[
\rho_{\mathrm{Sim}}(y \mid x, z_{\mathrm{C}})
:= \int \rho_{\mathrm{NL}}(y \mid x, z_{\mathrm{NL}})\, T(z_{\mathrm{NL}} \mid z_{\mathrm{C}})\, dz_{\mathrm{NL}}.
\]
Then the induced conditional output distribution under $(E_{\mathrm{Code}}, \rho_{\mathrm{Sim}})$ equals the conditional output distribution obtained by first sampling $Z_{\mathrm{C}} \sim p_{\mathrm{Code}}(\cdot \mid x)$, then sampling $Z_{\mathrm{NL}} \sim T(\cdot \mid Z_{\mathrm{C}})$, and finally applying $\rho_{\mathrm{NL}}$:
\[
P_{\rho_{\mathrm{Sim}}, E_{\mathrm{Code}}}(Y=y \mid X=x)
= \int \rho_{\mathrm{NL}}(y \mid x, z_{\mathrm{NL}})\, p_{\mathrm{translated}}(z_{\mathrm{NL}} \mid x)\, dz_{\mathrm{NL}}.
\]
In particular, for any bounded loss, the expected loss under $(E_{\mathrm{Code}},\rho_{\mathrm{Sim}})$ equals the expected loss under the translated experiment paired with $\rho_{\mathrm{NL}}$.

Thus,
\[
\mathbb{E}[\ell(Y_{\mathrm{Sim}}, X)] = \mathbb{E}[\ell(\hat{Y}_{\mathrm{translated}}, X)].
\]
\textbf{Step 2: Substitute translated NL and original NL via TV lemma.} Here we show that if two signals look similar, they perform similarly. Even if translated NL is not exactly native NL, bounded loss decision problems cannot exploit small distributional differences, a property of the continuity property of Bayes Risk. 

\yu{Is there a citation for TV lemma, there should be one?}
\begin{lemma}[TV Lemma]
Let $X \sim p(x)$. Let $Z \mid X = x \sim P_x$ and $Z' \mid X = x \sim Q_x$. Let $g(x, z) \in [0, 1]$ be measurable. Then
\[
\mathbb{E}[g(X, Z)] - \mathbb{E}[g(X, Z')] \leq \mathbb{E}_X \bigl[ d_{\mathrm{TV}}(P_X, Q_X) \bigr].
\]
\end{lemma}
For each $x$ and trace $z$, define $g(x, z) := \mathbb{E}_{y|x,z}[\ell(y, x)]$. Then $g(x, z) \in [0, 1]$. Note that
\begin{align*}
\mathbb{E}_{(Y_{\mathrm{NL}}, X)}[\ell(Y_{\mathrm{NL}}, X)] &= \mathbb{E}_{(X, Z_{\mathrm{NL}})}[g(X, Z_{\mathrm{NL}})], \\
\mathbb{E}_{(\hat Y_{\mathrm{Tr}}, X)}[\ell(\hat{Y}_{\mathrm{translated}}, X)] &= \mathbb{E}_{(X, \hat{Z}_{\mathrm{NL}})}[g(X, \hat{Z}_{\mathrm{NL}})].
\end{align*}

Applying the TV lemma with $P_x = p_{\mathrm{NL}}(\cdot \mid x)$ and $Q_x = p_{\mathrm{translated}}(\cdot \mid x)$:
\begin{align*}
&\bigl| \mathbb{E}[\ell(Y_{\mathrm{NL}}, X)] - \mathbb{E}[\ell(\hat{Y}_{\mathrm{translated}}, X)] \bigr| \\
&\quad = \bigl| \mathbb{E}[g(X, Z_{\mathrm{NL}})] - \mathbb{E}[g(X, \hat{Z}_{\mathrm{NL}})] \bigr| \\
&\quad \leq \mathbb{E}_X \bigl[ d_{\mathrm{TV}}(p_{\mathrm{NL}}(\cdot \mid X), \, p_{\mathrm{translated}}(\cdot \mid X)) \bigr]
\leq \varepsilon.
\end{align*}

Therefore, rearranging gives
\begin{align*}
&\mathbb{E}[\ell(\hat{Y}_{\mathrm{translated}}, X)] \leq \mathbb{E}[\ell(Y_{\mathrm{NL}}, X)] + \varepsilon \\
&\mathbb{E}[\ell(Y_{\mathrm{Sim}}, X)]
= \mathbb{E}[\ell(\hat{Y}_{\mathrm{translated}}, X)]
\leq \mathbb{E}[\ell(Y_{\mathrm{NL}}, X)] + \varepsilon.
\end{align*}
Since the construction above holds for an \emph{arbitrary} NL executor $\rho_{\mathrm{NL}} \in \mathcal{H}$, it also holds in particular for an NL executor that (approximately) minimizes risk under $E_{\mathrm{NL}}$. Let $\rho_{\mathrm{NL}}^* \in \arg\min_{\rho \in \mathcal{H}} \mathbb{E}[\ell(\hat Y, X)]$ under $E_{\mathrm{NL}}$, and let $\rho_{\mathrm{Sim}}^*$ be the induced executor on code traces obtained by composing $\rho_{\mathrm{NL}}^*$ with $T$:
\[
\rho_{\mathrm{Sim}}^*(y \mid x, z_{\mathrm{C}})
:= \int \rho_{\mathrm{NL}}^*(y \mid x, z_{\mathrm{NL}})\, T(z_{\mathrm{NL}} \mid z_{\mathrm{C}})\, dz_{\mathrm{NL}}.
\]
By Step~1 and Step~2,
\[
\mathbb{E}\bigl[\ell(\hat Y_{\mathrm{Sim}}^{(\rho_{\mathrm{Sim}}^*)}, X)\bigr]
\le
\mathbb{E}\bigl[\ell(\hat Y_{\mathrm{NL}}^{(\rho_{\mathrm{NL}}^*)}, X)\bigr] + \varepsilon.
\]
Finally, since $R^*(E_{\mathrm{Code}})$ is the infimum over \emph{all} executors in $\mathcal{H}$ applied to $E_{\mathrm{Code}}$, we have
\[
R^*(E_{\mathrm{Code}})
\le
\mathbb{E}\bigl[\ell(\hat Y_{\mathrm{Sim}}^{(\rho_{\mathrm{Sim}}^*)}, X)\bigr]
\le
R^*(E_{\mathrm{NL}}) + \varepsilon.
\]
\begin{framed}
\qquad \qquad \quad $R^*(E_{\mathrm{Code}}) \le R^*(E_{\mathrm{NL}}) + \varepsilon$
\end{framed}

\end{proof}

\vspace{-20pt}
\subsection{Arm~2 $<$ Arm~3}
We prove that deterministic execution in Arm 3 weakly dominates LLM simulation in Arm 2 under restricted decision rules. Crucially, this section does not leverage Blackwell dominance, since the experiment is the same. 
\yu{why only weakly as we see a large performance gap?}

\textbf{Setup.} Let $X \sim p(x)$ be a task instance and let $Y^*(x)$ denote the corresponding ground-truth. Suppose $Z_{\mathrm{Sim}} \sim p_{\mathrm{Sim}}$ is the code produced by the model. Let $g$ be a deterministic python3 runtime. Define the two arms:
\begin{align*}
    & \mathrm{Arm2}: Y_{\mathrm{Sim}} \sim \delta_{\mathrm{Sim}} (\cdot | X, Z_{\mathrm{Sim}}) \\
    & \mathrm{Arm3}: Y_{\mathrm{Exec}} := g(X, Z_{\mathrm{Sim}})
\end{align*}
\begin{proof}
Define the event
\[
C := \{ g(X, Z_{\mathrm{Sim}}) = Y^*(X) \},
\]
corresponding to semantically correct code.
Under $\ell(y,x)=\mathbf{1}\{y\neq Y^*(x)\}$, on the event $C$ the deterministic executor is correct with probability one:
\[
\Pr(Y_{\mathrm{Exec}} \neq Y^* \mid C) = 0.
\]
In contrast, even when $C$ holds, LLM simulation may incur error due to stochastic execution or reasoning noise:
\[
\Pr(Y_{\mathrm{Sim}} \neq Y^* \mid C) > 0.
\]

Therefore, conditional on semantically correct code, Arm~3 weakly dominates Arm~2 under representation-restricted Bayes risk.
\begin{framed}
\qquad \qquad \quad $R^*_3 \le R^*_2 \quad \text{conditional on } C$
\end{framed}
\end{proof}

The only scenario where Arm~2 could outperform Arm~3 is when the generated code is \emph{incorrect}, yet the LLM ``recovers'' by reasoning to the correct answer despite the flawed code. We empirically quantify this recovery rate below. 

\textbf{Recovery reduces as tasks get harder.}
To assess the practical impact of recovery, we empirically measure the frequency of such events as task difficulty increases:
\begin{enumerate}[leftmargin=*]
    \item Arm~3 produces an incorrect answer (implying incorrect code generation), and
    \item Arm~2 produces the correct answer (implying successful LLM recovery).
\end{enumerate}

\cref{fig:recovery_final} presents the recovery analysis across all tasks and models. The recovery rate remains consistently low (typically $< 5\%$), indicating that LLM simulation rarely compensates for code generation errors. This confirms that Arm~3's advantage stems from reliable solver execution rather than Arm~2's inability to reason about code.

\begin{figure}[t]
    \centering
    \vspace{-5pt}
    \includegraphics[width=0.85\linewidth]{images/recovery_final.png}
    \vspace{-5pt}
    \caption{\textbf{Recovery rate.} How often Arm~2 succeeds when Arm~3 fails. Recovery rates are $<$5\% across all tasks, confirming Arm~3's advantage comes from reliable execution, not LLM compensation.}
    \label{fig:recovery_final}
\end{figure}


