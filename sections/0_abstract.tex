\begin{abstract}
% Context: Establish the problem domain
Large language models can solve algorithmic problems either through direct natural language (NL) reasoning or by generating executable code delegated to an external solver. However, little progress has been made on \emph{understanding why}. Comparing NL reasoning and solver-based pipelines directly is ill-posed: they differ simultaneously in representation space and execution mechanism.
% Gap + Contribution: What's missing and what we provide
We introduce a three-route framework that makes this comparison tractable by introducing an intermediary step---code generation with LLM-based execution. This enables our empirical analysis which shows a statistically significant gap supporting code $>$ NL by +29.9\% across 44 different algorithmic tasks and 6 models. A statistical analysis indicates that natural-language reasoning does not provide additional decision-relevant information beyond what is already captured by code representations. Consequently, replacing NL traces with code traces incurs minimal performance loss, while enabling deterministic execution. A systematic comparison of LLM-based reasoning and external execution further shows that execution, rather than trace representation, is the primary performance bottleneck.

% A statistical interpretation of  Route 1 v.s. Route 2 \yu{Route 1 and 2 are not defined here}reveals that NL reasoning does not contain decision-relevant information beyond what is already in code, indicating reasoning trace generation is not the bottleneck for language\yu{bottleneck for what, for accurately solving the task?}. Rather, a systematic study on how language reasoning and code function elucidates trace execution as the bottleneck.   


% Building on these observations, we introduce a statistical and information theoretic analysis that proves code $>$ NL under mild assumptions. 

% These results inform the design of compositional AI systems, providing principled guidance on when to use tool-augmented versus monolithic reasoning for algorithmic tasks. Our framework offers a unified perspective on the tool-use versus direct-reasoning tradeoff. 


% \dr{Say something about the outcome of this analysis; you jump directly to experiments leaving the reader expecting something.}

% Results: Concrete findings
% Across 44 different algorithmic tasks and 6 models, we observe that there is statistically significant gap (p$<$0.001) between code and natural language reasoning ($>$25\%). 
% \dr{The second part of the abstract is too long. You don't need to say everything. Say that the theoretical framework is supported by extensive experimentation (give the first sentence above) and summarize the rest in 1-2 sentences or drop it, since you want to keep the last, impact, sentence.} 

% We find that code representations scale better, with 4.01$\times$ odds of correctness compared to natural language. Under causal intervention experiments, we identify natural language reasoning as a projection of deeper underlying algorithmic representations. Using this insight, we leverage Bayesian Inference and the Blackwell Dominance Principle to prove that the code execution route achieves lower Bayes Risk than natural language reasoning route.
% Impact: Why it matters

\end{abstract}

