\section{Three Arms Framework}
\label{sec:framework}

We introduce a unified framework for comparing natural-language reasoning and code-based reasoning in algorithmic tasks. The framework explicitly separates differences in \emph{information representation} from differences in \emph{execution}, enabling tractable and interpretable comparisons.

\subsection{Task and Loss}

Let $X \sim p(x)$ denote a task instance (problem statement and inputs), and let $Y^*(X) \in \mathcal{Y}$ denote the ground-truth output. We evaluate performance under $0$--$1$ loss
\[
\ell(y,x) := \mathbf{1}\{y \neq Y^*(x)\}.
\]

All risks are taken with respect to the test distribution $p(x)$.

\subsection{Trace Generators and Executors}

We model each reasoning pipeline as a two-stage stochastic process:

\paragraph{Trace generation (information structure).}
A trace (i.e. Chain-of-Thought) generator is a Markov kernel
\[
E : \mathcal{X} \to \Delta(\mathcal{Z}), \qquad
Z \sim p_E(z \mid x),
\]
which produces an auxiliary trace $Z$ given the task instance.

\paragraph{Execution (decision rule).}
An executor is a (possibly randomized) Markov kernel
\[
\rho : \mathcal{X} \times \mathcal{Z} \to \Delta(\mathcal{Y}),
\]
mapping the observed instance and trace to a final output.

The induced conditional output distribution is
\[
P_{\rho,E}(Y = y \mid X = x)
= \int \rho(y \mid x, z)\, p_E(z \mid x)\, dz .
\]

The population risk of a pipeline $(E,\rho)$ is
\begin{align*}
& R(E,\rho)
:= \mathbb{E}\bigl[\ell(\hat{Y}, X)\bigr],
\qquad \\
& Z \sim p_E(\cdot \mid X),\;
\hat{Y} \sim \rho(\cdot \mid X, Z).
\end{align*}

\subsection{Computation-Constrained Optimal Risk}

To reflect inference-time computational constraints, we evaluate executors within restricted families.
For a trace space $\mathcal{Z}$ (e.g. code or NL), let
\[
\mathcal{H}_{\mathcal{Z}} \subseteq
\{ \rho : \mathcal{X} \times \mathcal{Z} \to \Delta(\mathcal{Y}) \}
\]
denote a class of executors realizable under a fixed model family and bounded inference protocol.

We define the computation-constrained optimal risk of a trace generator $E$ as
\[
R^*_{\mathcal{H}}(E)
:= \inf_{\rho \in \mathcal{H}} R(E,\rho).
\]
This differs from classical Bayes risk, which optimizes over all measurable decision rules.

\subsection{The Three Arms}

We consider three reasoning pipelines (``arms''), each defined by a trace generator and an executor family.

\paragraph{Arm 1 (Natural Language).}
A natural-language trace generator $E_{\mathrm{NL}}$ produces traces
$Z_{\mathrm{NL}} \sim p_{\mathrm{NL}}(\cdot \mid X)$,
paired with an executor family
\[
\mathcal{H}_{\mathrm{NL}}
\subseteq
\{ \rho : \mathcal{X} \times \mathcal{Z}_{\mathrm{NL}} \to \Delta(\mathcal{Y}) \}.
\]

\paragraph{Arm 2 (Code + Simulation).}
A code trace generator $E_{\mathrm{Code}}$ produces executable representations
$Z_{\mathrm{C}} \sim p_{\mathrm{Code}}(\cdot \mid X)$,
paired with an executor family
\[
\mathcal{H}_{\mathrm{C}}
\subseteq
\{ \rho : \mathcal{X} \times \mathcal{Z}_{\mathrm{C}} \to \Delta(\mathcal{Y}) \}
\]
corresponding to language-model-based simulation of code execution.

\paragraph{Arm 3 (Code + Execution).}
Arm~3 uses the same code trace generator $E_{\mathrm{Code}}$ as Arm~2, but pairs it with a deterministic executor corresponding to external code execution.

\subsection{Interpretation of Comparisons}

In all arms, the executor observes the full task instance $X$; the trace $Z$ provides auxiliary information. Accordingly, comparisons between arms are conditional on $X$ and should be interpreted as statements about what auxiliary representations can be simulated from others, and how execution mechanisms affect achievable risk.

Performance comparisons are expressed in terms of computation-constrained optimal risks $R^*_{\mathcal{H}}(E)$, which isolate differences due to representation and execution under fixed inference constraints.

\subsection{Roadmap}

Section~\ref{sec:eval} instantiates this framework with concrete models, prompts, datasets, and statistical tests. Section~\ref{sec:exp_similarity} provides empirical evidence motivating assumptions about the relationship between natural-language and code traces. Section~\ref{sec:theory} analyzes the three arms theoretically within this framework.
