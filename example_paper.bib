@inproceedings{poole2019variational,
  title={On variational bounds of mutual information},
  author={Poole, Ben and Ozair, Sherjil and Van Den Oord, Aaron and Alemi, Alex and Tucker, George},
  booktitle={International conference on machine learning},
  pages={5171--5180},
  year={2019},
  organization={PMLR}
}
@article{xie2021explanation,
  title={An explanation of in-context learning as implicit bayesian inference},
  author={Xie, Sang Michael and Raghunathan, Aditi and Liang, Percy and Ma, Tengyu},
  journal={arXiv preprint arXiv:2111.02080},
  year={2021}
}
@article{bai2023transformers,
  title={Transformers as statisticians: Provable in-context learning with in-context algorithm selection},
  author={Bai, Yu and Chen, Fan and Wang, Huan and Xiong, Caiming and Mei, Song},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={57125--57211},
  year={2023}
}

@article{ton2024understanding,
  title={Understanding chain-of-thought in llms through information theory},
  author={Ton, Jean-Francois and Taufiq, Muhammad Faaiz and Liu, Yang},
  journal={arXiv preprint arXiv:2411.11984},
  year={2024}
}
@article{altabaa2025cot,
  title={CoT Information: Improved Sample Complexity under Chain-of-Thought Supervision},
  author={Altabaa, Awni and Montasser, Omar and Lafferty, John},
  journal={arXiv preprint arXiv:2505.15927},
  year={2025}
}

@inproceedings{gao2023pal,
  title={Pal: Program-aided language models},
  author={Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  booktitle={International Conference on Machine Learning},
  pages={10764--10799},
  year={2023},
  organization={PMLR}
}
@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@inproceedings{lyu2023faithful,
  title={Faithful chain-of-thought reasoning},
  author={Lyu, Qing and Havaldar, Shreya and Stein, Adam and Zhang, Li and Rao, Delip and Wong, Eric and Apidianaki, Marianna and Callison-Burch, Chris},
  booktitle={The 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (IJCNLP-AACL 2023)},
  year={2023}
}

@article{pan2023logic,
  title={Logic-lm: Empowering large language models with symbolic solvers for faithful logical reasoning},
  author={Pan, Liangming and Albalak, Alon and Wang, Xinyi and Wang, William Yang},
  journal={arXiv preprint arXiv:2305.12295},
  year={2023}
}

@article{merrill2023expressive,
  title={The expressive power of transformers with chain of thought},
  author={Merrill, William and Sabharwal, Ashish},
  journal={arXiv preprint arXiv:2310.07923},
  year={2023}
}



@article{graves_hybrid_2016,
	title = {Hybrid computing using a neural network with dynamic external memory},
	volume = {538},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/nature20101},
	doi = {10.1038/nature20101},
	language = {en},
	number = {7626},
	urldate = {2025-06-18},
	journal = {Nature},
	author = {Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwińska, Agnieszka and Colmenarejo, Sergio Gómez and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and Badia, Adrià Puigdomènech and Hermann, Karl Moritz and Zwols, Yori and Ostrovski, Georg and Cain, Adam and King, Helen and Summerfield, Christopher and Blunsom, Phil and Kavukcuoglu, Koray and Hassabis, Demis},
	month = oct,
	year = {2016},
	pages = {471--476},
	file = {PDF:/Users/terrytong/Zotero/storage/MWRQCJV9/Graves et al. - 2016 - Hybrid computing using a neural network with dynamic external memory.pdf:application/pdf},
}


@misc{graves_neural_2014,
	title = {Neural {Turing} {Machines}},
	url = {http://arxiv.org/abs/1410.5401},
	doi = {10.48550/arXiv.1410.5401},
	abstract = {We extend the capabilities of neural networks by coupling them to external memory resources, which they can interact with by attentional processes. The combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-to-end, allowing it to be efficiently trained with gradient descent. Preliminary results demonstrate that Neural Turing Machines can infer simple algorithms such as copying, sorting, and associative recall from input and output examples.},
	urldate = {2025-06-17},
	publisher = {arXiv},
	author = {Graves, Alex and Wayne, Greg and Danihelka, Ivo},
	month = dec,
	year = {2014},
	note = {arXiv:1410.5401 [cs]},
	keywords = {Computer Science - Neural and Evolutionary Computing},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/GYYRKNZX/Graves et al. - 2014 - Neural Turing Machines.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/Y9I4XWH9/1410.html:text/html},
}

@misc{reed_neural_2016,
	title = {Neural {Programmer}-{Interpreters}},
	url = {http://arxiv.org/abs/1511.06279},
	doi = {10.48550/arXiv.1511.06279},
	abstract = {We propose the neural programmer-interpreter (NPI): a recurrent and compositional neural network that learns to represent and execute programs. NPI has three learnable components: a task-agnostic recurrent core, a persistent key-value program memory, and domain-specific encoders that enable a single NPI to operate in multiple perceptually diverse environments with distinct affordances. By learning to compose lower-level programs to express higher-level programs, NPI reduces sample complexity and increases generalization ability compared to sequence-to-sequence LSTMs. The program memory allows efficient learning of additional tasks by building on existing programs. NPI can also harness the environment (e.g. a scratch pad with read-write pointers) to cache intermediate results of computation, lessening the long-term memory burden on recurrent hidden units. In this work we train the NPI with fully-supervised execution traces; each program has example sequences of calls to the immediate subprograms conditioned on the input. Rather than training on a huge number of relatively weak labels, NPI learns from a small number of rich examples. We demonstrate the capability of our model to learn several types of compositional programs: addition, sorting, and canonicalizing 3D models. Furthermore, a single NPI learns to execute these programs and all 21 associated subprograms.},
	urldate = {2025-06-18},
	publisher = {arXiv},
	author = {Reed, Scott and Freitas, Nando de},
	month = feb,
	year = {2016},
	note = {arXiv:1511.06279 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Important},
	annote = {Comment: ICLR 2016 conference submission},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/P77NX8QI/Reed and Freitas - 2016 - Neural Programmer-Interpreters.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/YHMM7WY3/1511.html:text/html},
}


%cogsci
@article{schneider_controlled_2003,
	title = {Controlled \& automatic processing: behavior, theory, and biological mechanisms},
	volume = {27},
	issn = {0364-0213, 1551-6709},
	shorttitle = {Controlled \& automatic processing},
	url = {https://onlinelibrary.wiley.com/doi/10.1207/s15516709cog2703_8},
	doi = {10.1207/s15516709cog2703_8},
	abstract = {This paper provides an overview of developments in a dual processing theory of automatic and controlled processing that began with the empirical and theoretical work described by Schneider and Shiffrin (1977) and Shiffrin and Schneider (1977) over a quarter century ago. A review of relevant empirical ﬁndings suggests that there is a set of core behavioral phenomena reﬂecting differences between controlled and automatic processing that must be addressed by a successful theory. These phenomena relate to: consistency in training, serial versus parallel processing, level of effort, robustness to stressors, degree of control, effects on long-term memory, and priority encoding. We detail a computational model of controlled processing, CAP2, that accounts for these phenomena as emergent properties of an underlying hybrid computational architecture. The model employs a large network of distributed data modules that can categorize, buffer, associate, and prioritize information. Each module is a connectionist network with input and output layers, and each module communicates with a central Control System by outputting priority and activity report signals, and by receiving control signals. The Control System is composed of ﬁve processors including a Goal Processor, an Attention Controller, an Activity Monitor, an Episodic Store, and a Gating \& Report Relay. The transition from controlled to automatic processing occurs in this model as the data modules become capable of transmitting their output without mediation by the Control System. We describe recent progress in mapping the components of this model onto speciﬁc neuroanatomical substrates, brieﬂy discuss the potential for applying functional neuroimaging techniques to test the model’s predictions, and its relation to other models.},
	language = {en},
	number = {3},
	urldate = {2025-06-19},
	journal = {Cognitive Science},
	author = {Schneider, Walter and Chein, Jason M.},
	month = may,
	year = {2003},
	pages = {525--559},
	annote = {Notes:


Dual Processing Theory, controlled and automatic. 


},
	file = {PDF:/Users/terrytong/Zotero/storage/M873GHLM/Schneider and Chein - 2003 - Controlled & automatic processing behavior, theory, and biological mechanisms.pdf:application/pdf},
}

@article{anderson_neural_2010,
	title = {Neural reuse: {A} fundamental organizational principle of the brain},
	volume = {33},
	copyright = {https://www.cambridge.org/core/terms},
	issn = {0140-525X, 1469-1825},
	shorttitle = {Neural reuse},
	url = {https://www.cambridge.org/core/product/identifier/S0140525X10000853/type/journal_article},
	doi = {10.1017/S0140525X10000853},
	abstract = {An emerging class of theories concerning the functional structure of the brain takes the reuse of neural circuitry for various cognitive purposes to be a central organizational principle. According to these theories, it is quite common for neural circuits established for one purpose to be exapted (exploited, recycled, redeployed) during evolution or normal development, and be put to different uses, often without losing their original functions. Neural reuse theories thus differ from the usual understanding of the role of neural plasticity (which is, after all, a kind of reuse) in brain organization along the following lines: According to neural reuse, circuits can continue to acquire new uses after an initial or original function is established; the acquisition of new uses need not involve unusual circumstances such as injury or loss of established function; and the acquisition of a new use need not involve (much) local change to circuit structure (e.g., it might involve only the establishment of functional connections to new neural partners). Thus, neural reuse theories offer a distinct perspective on several topics of general interest, such as: the evolution and development of the brain, including (for instance) the evolutionary-developmental pathway supporting primate tool use and human language; the degree of modularity in brain organization; the degree of localization of cognitive function; and the cortical parcellation problem and the prospects (and proper methods to employ) for function to structure mapping. The idea also has some practical implications in the areas of rehabilitative medicine and machine interface design.},
	language = {en},
	number = {4},
	urldate = {2025-06-19},
	journal = {Behavioral and Brain Sciences},
	author = {Anderson, Michael L.},
	month = aug,
	year = {2010},
	pages = {245--266},
	file = {PDF:/Users/terrytong/Zotero/storage/GD7CZYIQ/Anderson - 2010 - Neural reuse A fundamental organizational principle of the brain.pdf:application/pdf},
}

@article{risko_cognitive_2016,
	title = {Cognitive {Offloading}},
	volume = {20},
	issn = {13646613},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661316300985},
	doi = {10.1016/j.tics.2016.07.002},
	language = {en},
	number = {9},
	urldate = {2025-06-19},
	journal = {Trends in Cognitive Sciences},
	author = {Risko, Evan F. and Gilbert, Sam J.},
	month = sep,
	year = {2016},
	pages = {676--688},
	annote = {Allows users to reallocate attention etc to other areas like reasoning and planning. 
},
	file = {PDF:/Users/terrytong/Zotero/storage/LRT8Y7LC/Risko and Gilbert - 2016 - Cognitive Offloading.pdf:application/pdf},
}

@article{vaesen_cognitive_2012,
	title = {The cognitive bases of human tool use},
	volume = {35},
	copyright = {https://www.cambridge.org/core/terms},
	issn = {0140-525X, 1469-1825},
	url = {https://www.cambridge.org/core/product/identifier/S0140525X11001452/type/journal_article},
	doi = {10.1017/S0140525X11001452},
	abstract = {This article has two goals. The first is to assess, in the face of accruing reports on the ingenuity of great ape tool use, whether and in what sense human tool use still evidences unique, higher cognitive ability. To that effect, I offer a systematic comparison between humans and nonhuman primates with respect to nine cognitive capacities deemed crucial to tool use: enhanced hand–eye coordination, body schema plasticity, causal reasoning, function representation, executive control, social learning, teaching, social intelligence, and language. Since striking differences between humans and great apes stand firm in eight out of nine of these domains, I conclude that human tool use still marks a major cognitive discontinuity between us and our closest relatives. As a second goal of the paper, I address the evolution of human technologies. In particular, I show how the cognitive traits reviewed help to explain why technological accumulation evolved so markedly in humans, and so modestly in apes.},
	language = {en},
	number = {4},
	urldate = {2025-06-19},
	journal = {Behavioral and Brain Sciences},
	author = {Vaesen, Krist},
	month = aug,
	year = {2012},
	pages = {203--218},
	file = {PDF:/Users/terrytong/Zotero/storage/R3RN23JD/Vaesen - 2012 - The cognitive bases of human tool use.pdf:application/pdf},
}

@article{rumelhart_general_nodate,
	title = {A {General} {Framework} for {Parallel} {Distributed} {Processing}},
	language = {en},
	author = {Rumelhart, D E and Hinton, G E and McCLELLAND, L},
	file = {PDF:/Users/terrytong/Zotero/storage/ZXFN4CBY/Rumelhart et al. - A General Framework for Parallel Distributed Processing.pdf:application/pdf},
}

@article{schmidhuber_formal_2010,
	title = {Formal {Theory} of {Creativity}, {Fun}, and {Intrinsic} {Motivation} (1990–2010)},
	volume = {2},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1943-0604, 1943-0612},
	url = {http://ieeexplore.ieee.org/document/5508364/},
	doi = {10.1109/TAMD.2010.2056368},
	abstract = {The simple but general formal theory of fun \& intrinsic motivation \& creativity (1990-) is based on the concept of maximizing intrinsic reward for the active creation or discovery of novel, surprising patterns allowing for improved prediction or data compression. It generalizes the traditional ﬁeld of active learning, and is related to old but less formal ideas in aesthetics theory and developmental psychology. It has been argued that the theory explains many essential aspects of intelligence including autonomous development, science, art, music, humor. This overview ﬁrst describes theoretically optimal (but not necessarily practical) ways of implementing the basic computational principles on exploratory, intrinsically motivated agents or robots, encouraging them to provoke event sequences exhibiting previously unknown but learnable algorithmic regularities. Emphasis is put on the importance of limited computational resources for online prediction and compression. Discrete and continuous time formulations are given. Previous practical but non-optimal implementations (1991, 1995, 1997-2002) are reviewed, as well as several recent variants by others (2005-). A simpliﬁed typology addresses current confusion concerning the precise nature of intrinsic motivation.},
	language = {en},
	number = {3},
	urldate = {2025-06-24},
	journal = {IEEE Transactions on Autonomous Mental Development},
	author = {Schmidhuber, Jürgen},
	month = sep,
	year = {2010},
	pages = {230--247},
	file = {PDF:/Users/terrytong/Zotero/storage/Q4EB4HL8/Schmidhuber - 2010 - Formal Theory of Creativity, Fun, and Intrinsic Motivation (1990–2010).pdf:application/pdf},
}

%heirarchical RL


@article{dietterich_hierarchical_2000,
	title = {Hierarchical {Reinforcement} {Learning} with the {MAXQ} {Value} {Function} {Decomposition}},
	volume = {13},
	copyright = {Copyright (c)},
	issn = {1076-9757},
	url = {https://www.jair.org/index.php/jair/article/view/10266},
	doi = {10.1613/jair.639},
	abstract = {This paper presents a new approach to hierarchical    reinforcement learning based on decomposing the target Markov decision    process (MDP) into a hierarchy of smaller MDPs and decomposing the    value function of the target MDP into an additive combination of the    value functions of the smaller MDPs.  The decomposition, known as the    MAXQ decomposition, has both a procedural semantics---as a subroutine    hierarchy---and a declarative semantics---as a representation of the    value function of a hierarchical policy.  MAXQ unifies and extends    previous work on hierarchical reinforcement learning by Singh,    Kaelbling, and Dayan and Hinton.  It is based on the assumption that    the programmer can identify useful subgoals and define subtasks that    achieve these subgoals.  By defining such subgoals, the programmer    constrains the set of policies that need to be considered during    reinforcement learning.  The MAXQ value function decomposition can    represent the value function of any policy that is consistent with the    given hierarchy.  The decomposition also creates opportunities to    exploit state abstractions, so that individual MDPs within the    hierarchy can ignore large parts of the state space.  This is    important for the practical application of the method.  This paper    defines the MAXQ hierarchy, proves formal results on its    representational power, and establishes five conditions for the safe    use of state abstractions.  The paper presents an online model-free    learning algorithm, MAXQ-Q, and proves that it converges with    probability 1 to a kind of locally-optimal policy known as a    recursively optimal policy, even in the presence of the five kinds of    state abstraction.  The paper evaluates the MAXQ representation and    MAXQ-Q through a series of experiments in three domains and shows    experimentally that MAXQ-Q (with state abstractions) converges to a    recursively optimal policy much faster than flat Q learning.  The fact    that MAXQ learns a representation of the value function has an    important benefit: it makes it possible to compute and execute an    improved, non-hierarchical policy via a procedure similar to the    policy improvement step of policy iteration.  The paper demonstrates    the effectiveness of this non-hierarchical execution experimentally.    Finally, the paper concludes with a comparison to related work and a    discussion of the design tradeoffs in hierarchical reinforcement learning.},
	language = {en},
	urldate = {2025-06-19},
	journal = {Journal of Artificial Intelligence Research},
	author = {Dietterich, T. G.},
	month = nov,
	year = {2000},
	pages = {227--303},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/YUDAIMLU/Dietterich - 2000 - Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition.pdf:application/pdf},
}

@article{knoblock_learning_nodate,
	title = {Learning {Abstraction} {Hierarchies} for {Problem} {Solving}},
	abstract = {The use of abstraction in problem solving is an e ective approach to reducing search, but nding good abstractions is a di cult problem, even for people. This paper identi es a criterion for selecting useful abstractions, describes a tractable algorithm for generating them, and empirically demonstrates that the abstractions reduce search. The abstraction learner, called alpine, is integrated with the prodigy problem solver [Minton et al., 1989b, Carbonell et al., 1991] and has been tested on large problem sets in multiple domains.},
	language = {en},
	author = {Knoblock, Craig A},
	file = {PDF:/Users/terrytong/Zotero/storage/N2PICV9Z/Knoblock - Learning Abstraction Hierarchies for Problem Solving.pdf:application/pdf},
}

@inproceedings{kolter_hierarchical_2007,
	title = {Hierarchical {Apprenticeship} {Learning} with {Application} to {Quadruped} {Locomotion}},
	volume = {20},
	url = {https://proceedings.neurips.cc/paper_files/paper/2007/hash/54a367d629152b720749e187b3eaa11b-Abstract.html},
	abstract = {We consider apprenticeship learning—learning from expert demonstrations—in the setting of large, complex domains. Past work in apprenticeship learning requires that the expert demonstrate complete trajectories through the domain. However, in many problems even an expert has difﬁculty controlling the system, which makes this approach infeasible. For example, consider the task of teach- ing a quadruped robot to navigate over extreme terrain; demonstrating an optimal policy (i.e., an optimal set of foot locations over the entire terrain) is a highly non-trivial task, even for an expert. In this paper we propose a method for hier- archical apprenticeship learning, which allows the algorithm to accept isolated advice at different hierarchical levels of the control task. This type of advice is often feasible for experts to give, even if the expert is unable to demonstrate com- plete trajectories. This allows us to extend the apprenticeship learning paradigm to much larger, more challenging domains. In particular, in this paper we apply the hierarchical apprenticeship learning algorithm to the task of quadruped loco- motion over extreme terrain, and achieve, to the best of our knowledge, results superior to any previously published work.},
	urldate = {2025-06-19},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Kolter, J. and Abbeel, Pieter and Ng, Andrew},
	year = {2007},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/TUJ43AXP/Kolter et al. - 2007 - Hierarchical Apprenticeship Learning with Application to Quadruped Locomotion.pdf:application/pdf},
}




%compositionality

@misc{pierrot_learning_2021,
	title = {Learning {Compositional} {Neural} {Programs} with {Recursive} {Tree} {Search} and {Planning}},
	url = {http://arxiv.org/abs/1905.12941},
	doi = {10.48550/arXiv.1905.12941},
	abstract = {We propose a novel reinforcement learning algorithm, AlphaNPI, that incorporates the strengths of Neural Programmer-Interpreters (NPI) and AlphaZero. NPI contributes structural biases in the form of modularity, hierarchy and recursion, which are helpful to reduce sample complexity, improve generalization and increase interpretability. AlphaZero contributes powerful neural network guided search algorithms, which we augment with recursion. AlphaNPI only assumes a hierarchical program specification with sparse rewards: 1 when the program execution satisfies the specification, and 0 otherwise. Using this specification, AlphaNPI is able to train NPI models effectively with RL for the first time, completely eliminating the need for strong supervision in the form of execution traces. The experiments show that AlphaNPI can sort as well as previous strongly supervised NPI variants. The AlphaNPI agent is also trained on a Tower of Hanoi puzzle with two disks and is shown to generalize to puzzles with an arbitrary number of disk},
	urldate = {2025-06-19},
	publisher = {arXiv},
	author = {Pierrot, Thomas and Ligner, Guillaume and Reed, Scott and Sigaud, Olivier and Perrin, Nicolas and Laterre, Alexandre and Kas, David and Beguir, Karim and Freitas, Nando de},
	month = apr,
	year = {2021},
	note = {arXiv:1905.12941 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/CK2LP2NR/Pierrot et al. - 2021 - Learning Compositional Neural Programs with Recursive Tree Search and Planning.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/IR5MU9HG/1905.html:text/html},
}

@misc{hudson_compositional_2018,
	title = {Compositional {Attention} {Networks} for {Machine} {Reasoning}},
	url = {http://arxiv.org/abs/1803.03067},
	doi = {10.48550/arXiv.1803.03067},
	abstract = {We present the MAC network, a novel fully differentiable neural network architecture, designed to facilitate explicit and expressive reasoning. MAC moves away from monolithic black-box neural architectures towards a design that encourages both transparency and versatility. The model approaches problems by decomposing them into a series of attention-based reasoning steps, each performed by a novel recurrent Memory, Attention, and Composition (MAC) cell that maintains a separation between control and memory. By stringing the cells together and imposing structural constraints that regulate their interaction, MAC effectively learns to perform iterative reasoning processes that are directly inferred from the data in an end-to-end approach. We demonstrate the model's strength, robustness and interpretability on the challenging CLEVR dataset for visual reasoning, achieving a new state-of-the-art 98.9\% accuracy, halving the error rate of the previous best model. More importantly, we show that the model is computationally-efficient and data-efficient, in particular requiring 5x less data than existing models to achieve strong results.},
	urldate = {2025-06-20},
	publisher = {arXiv},
	author = {Hudson, Drew A. and Manning, Christopher D.},
	month = apr,
	year = {2018},
	note = {arXiv:1803.03067 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	annote = {Controller, Memory and Attention. No External Programs though
},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/UZ6JV2NX/Hudson and Manning - 2018 - Compositional Attention Networks for Machine Reasoning.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/E4FWJEVA/1803.html:text/html},
}

@misc{andreas_neural_2017,
	title = {Neural {Module} {Networks}},
	url = {http://arxiv.org/abs/1511.02799},
	doi = {10.48550/arXiv.1511.02799},
	abstract = {Visual question answering is fundamentally compositional in nature---a question like "where is the dog?" shares substructure with questions like "what color is the dog?" and "where is the cat?" This paper seeks to simultaneously exploit the representational capacity of deep networks and the compositional linguistic structure of questions. We describe a procedure for constructing and learning *neural module networks*, which compose collections of jointly-trained neural "modules" into deep networks for question answering. Our approach decomposes questions into their linguistic substructures, and uses these structures to dynamically instantiate modular networks (with reusable components for recognizing dogs, classifying colors, etc.). The resulting compound networks are jointly trained. We evaluate our approach on two challenging datasets for visual question answering, achieving state-of-the-art results on both the VQA natural image dataset and a new dataset of complex questions about abstract shapes.},
	urldate = {2025-06-20},
	publisher = {arXiv},
	author = {Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
	month = jul,
	year = {2017},
	note = {arXiv:1511.02799 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Corrects an error in the evaluation of the NMN-only ablation experiment},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/SIT2KCQS/Andreas et al. - 2017 - Neural Module Networks.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/TAHTUUJY/1511.html:text/html},
}

@misc{ram_what_2024,
	title = {What makes {Models} {Compositional}? {A} {Theoretical} {View}: {With} {Supplement}},
	shorttitle = {What makes {Models} {Compositional}?},
	url = {http://arxiv.org/abs/2405.02350},
	doi = {10.48550/arXiv.2405.02350},
	abstract = {Compositionality is thought to be a key component of language, and various compositional benchmarks have been developed to empirically probe the compositional generalization of existing sequence processing models. These benchmarks often highlight failures of existing models, but it is not clear why these models fail in this way. In this paper, we seek to theoretically understand the role the compositional structure of the models plays in these failures and how this structure relates to their expressivity and sample complexity. We propose a general neuro-symbolic definition of compositional functions and their compositional complexity. We then show how various existing general and special purpose sequence processing models (such as recurrent, convolution and attention-based ones) fit this definition and use it to analyze their compositional complexity. Finally, we provide theoretical guarantees for the expressivity and systematic generalization of compositional models that explicitly depend on our proposed definition and highlighting factors which drive poor empirical performance.},
	urldate = {2025-06-24},
	publisher = {arXiv},
	author = {Ram, Parikshit and Klinger, Tim and Gray, Alexander G.},
	month = may,
	year = {2024},
	note = {arXiv:2405.02350 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Important},
	annote = {Comment: Extended version of the original IJCAI 2024 paper with detailed supplementary materials (27 pages, 7 figures)},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/NY8CH5B8/Ram et al. - 2024 - What makes Models Compositional A Theoretical View With Supplement.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/WV7HC2S6/2405.html:text/html},
}

@article{ito_compositional_nodate,
	title = {Compositional generalization through abstract representations in human and artiﬁcial neural networks},
	abstract = {Humans have a remarkable ability to rapidly generalize to new tasks that is difﬁcult to reproduce in artiﬁcial learning systems. Compositionality has been proposed as a key mechanism supporting generalization in humans, but evidence of its neural implementation and impact on behavior is still scarce. Here we study the computational properties associated with compositional generalization in both humans and artiﬁcial neural networks (ANNs) on a highly compositional task. First, we identiﬁed behavioral signatures of compositional generalization in humans, along with their neural correlates using whole-cortex functional magnetic resonance imaging (fMRI) data. Next, we designed pretraining paradigms aided by a procedure we term primitives pretraining to endow compositional task elements into ANNs. We found that ANNs with this prior knowledge had greater correspondence with human behavior and neural compositional signatures. Importantly, primitives pretraining induced abstract internal representations, excellent zero-shot generalization, and sample-efﬁcient learning. Moreover, it gave rise to a hierarchy of abstract representations that matched human fMRI data, where sensory rule abstractions emerged in early sensory areas, and motor rule abstractions emerged in later motor areas. Our ﬁndings give empirical support to the role of compositional generalization in human behavior, implicate abstract representations as its neural implementation, and illustrate that these representations can be embedded into ANNs by designing simple and efﬁcient pretraining procedures.},
	language = {en},
	author = {Ito, Takuya and Klinger, Tim and Schultz, Douglas H and Murray, John D and Cole, Michael W and Rigotti, Mattia},
	file = {PDF:/Users/terrytong/Zotero/storage/IFW427GR/Ito et al. - Compositional generalization through abstract representations in human and artiﬁcial neural networks.pdf:application/pdf},
}

@misc{hupkes_compositionality_2020,
	title = {Compositionality decomposed: how do neural networks generalise?},
	shorttitle = {Compositionality decomposed},
	url = {http://arxiv.org/abs/1908.08351},
	doi = {10.48550/arXiv.1908.08351},
	abstract = {Despite a multitude of empirical studies, little consensus exists on whether neural networks are able to generalise compositionally, a controversy that, in part, stems from a lack of agreement about what it means for a neural model to be compositional. As a response to this controversy, we present a set of tests that provide a bridge between, on the one hand, the vast amount of linguistic and philosophical theory about compositionality of language and, on the other, the successful neural models of language. We collect different interpretations of compositionality and translate them into five theoretically grounded tests for models that are formulated on a task-independent level. In particular, we provide tests to investigate (i) if models systematically recombine known parts and rules (ii) if models can extend their predictions beyond the length they have seen in the training data (iii) if models' composition operations are local or global (iv) if models' predictions are robust to synonym substitutions and (v) if models favour rules or exceptions during training. To demonstrate the usefulness of this evaluation paradigm, we instantiate these five tests on a highly compositional data set which we dub PCFG SET and apply the resulting tests to three popular sequence-to-sequence models: a recurrent, a convolution-based and a transformer model. We provide an in-depth analysis of the results, which uncover the strengths and weaknesses of these three architectures and point to potential areas of improvement.},
	urldate = {2025-06-24},
	publisher = {arXiv},
	author = {Hupkes, Dieuwke and Dankers, Verna and Mul, Mathijs and Bruni, Elia},
	month = feb,
	year = {2020},
	note = {arXiv:1908.08351 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/XHMBMZNJ/Hupkes et al. - 2020 - Compositionality decomposed how do neural networks generalise.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/RR9UQRU2/1908.html:text/html},
}

@misc{elmoznino_complexity-based_2025,
	title = {A {Complexity}-{Based} {Theory} of {Compositionality}},
	url = {http://arxiv.org/abs/2410.14817},
	doi = {10.48550/arXiv.2410.14817},
	abstract = {Compositionality is believed to be fundamental to intelligence. In humans, it underlies the structure of thought, language, and higher-level reasoning. In AI, compositional representations can enable a powerful form of out-of-distribution generalization, in which a model systematically adapts to novel combinations of known concepts. However, while we have strong intuitions about what compositionality is, there currently exists no formal definition for it that is measurable and mathematical. Here, we propose such a definition, which we call representational compositionality, that accounts for and extends our intuitions about compositionality. The definition is conceptually simple, quantitative, grounded in algorithmic information theory, and applicable to any representation. Intuitively, representational compositionality states that a compositional representation satisfies three properties. First, it must be expressive. Second, it must be possible to re-describe the representation as a function of discrete symbolic sequences with re-combinable parts, analogous to sentences in natural language. Third, the function that relates these symbolic sequences to the representation, analogous to semantics in natural language, must be simple. Through experiments on both synthetic and real world data, we validate our definition of compositionality and show how it unifies disparate intuitions from across the literature in both AI and cognitive science. We also show that representational compositionality, while theoretically intractable, can be readily estimated using standard deep learning tools. Our definition has the potential to inspire the design of novel, theoretically-driven models that better capture the mechanisms of compositional thought.},
	urldate = {2025-08-04},
	publisher = {arXiv},
	author = {Elmoznino, Eric and Jiralerspong, Thomas and Bengio, Yoshua and Lajoie, Guillaume},
	month = feb,
	year = {2025},
	note = {arXiv:2410.14817 [cs]
version: 4},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/HXSWSU3Y/Elmoznino et al. - 2025 - A Complexity-Based Theory of Compositionality.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/LQMSWTBF/2410.html:text/html},
}
@article{poggio2017and,
  title={Why and when can deep-but not shallow-networks avoid the curse of dimensionality: a review},
  author={Poggio, Tomaso and Mhaskar, Hrushikesh and Rosasco, Lorenzo and Miranda, Brando and Liao, Qianli},
  journal={International Journal of Automation and Computing},
  volume={14},
  number={5},
  pages={503--519},
  year={2017},
  publisher={Springer}
}

% neural algs

@article{rodionov_discrete_nodate,
	title = {Discrete {Neural} {Algorithmic} {Reasoning}},
	abstract = {Neural algorithmic reasoning aims to capture computations with neural networks by training models to imitate the execution of classic algorithms. While common architectures are expressive enough to contain the correct model in the weights space, current neural reasoners struggle to generalize well on out-of-distribution data. On the other hand, classic computations are not affected by distributional shifts as they can be described as transitions between discrete computational states. In this work, we propose to force neural reasoners to maintain the execution trajectory as a combination of finite predefined states. To achieve this, we separate discrete and continuous data flows and describe the interaction between them. Trained with supervision on the algorithm’s state transitions, such models are able to perfectly align with the original algorithm. To show this, we evaluate our approach on multiple algorithmic problems and achieve perfect test scores both in single-task and multitask setups. Moreover, the proposed architectural choice allows us to prove the correctness of the learned algorithms for any test data.},
	language = {en},
	author = {Rodionov, Gleb and Prokhorenkova, Liudmila},
	file = {PDF:/Users/terrytong/Zotero/storage/D6KWWARV/Rodionov and Prokhorenkova - Discrete Neural Algorithmic Reasoning.pdf:application/pdf},
}

@misc{mahdavi_towards_2023,
	title = {Towards {Better} {Out}-of-{Distribution} {Generalization} of {Neural} {Algorithmic} {Reasoning} {Tasks}},
	url = {http://arxiv.org/abs/2211.00692},
	doi = {10.48550/arXiv.2211.00692},
	abstract = {In this paper, we study the OOD generalization of neural algorithmic reasoning tasks, where the goal is to learn an algorithm (e.g., sorting, breadth-first search, and depth-first search) from input-output pairs using deep neural networks. First, we argue that OOD generalization in this setting is significantly different than common OOD settings. For example, some phenomena in OOD generalization of image classifications such as {\textbackslash}emph\{accuracy on the line\} are not observed here, and techniques such as data augmentation methods do not help as assumptions underlying many augmentation techniques are often violated. Second, we analyze the main challenges (e.g., input distribution shift, non-representative data generation, and uninformative validation metrics) of the current leading benchmark, i.e., CLRS {\textbackslash}citep\{deepmind2021clrs\}, which contains 30 algorithmic reasoning tasks. We propose several solutions, including a simple-yet-effective fix to the input distribution shift and improved data generation. Finally, we propose an attention-based 2WL-graph neural network (GNN) processor which complements message-passing GNNs so their combination outperforms the state-of-the-art model by a 3\% margin averaged over all algorithms. Our code is available at: {\textbackslash}url\{https://github.com/smahdavi4/clrs\}.},
	urldate = {2025-06-24},
	publisher = {arXiv},
	author = {Mahdavi, Sadegh and Swersky, Kevin and Kipf, Thomas and Hashemi, Milad and Thrampoulidis, Christos and Liao, Renjie},
	month = mar,
	year = {2023},
	note = {arXiv:2211.00692 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Transactions on Machine Learning Research (TMLR), 2023},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/P7V36NF5/Mahdavi et al. - 2023 - Towards Better Out-of-Distribution Generalization of Neural Algorithmic Reasoning Tasks.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/CJZ9LJ4C/2211.html:text/html},
}

@article{velickovic_neural_2021,
	title = {Neural algorithmic reasoning},
	volume = {2},
	issn = {26663899},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2666389921000994},
	doi = {10.1016/j.patter.2021.100273},
	language = {en},
	number = {7},
	urldate = {2025-06-24},
	journal = {Patterns},
	author = {Veličković, Petar and Blundell, Charles},
	month = jul,
	year = {2021},
	pages = {100273},
	file = {PDF:/Users/terrytong/Zotero/storage/EVVAHZRE/Veličković and Blundell - 2021 - Neural algorithmic reasoning.pdf:application/pdf},
}

@article{georgiev_neural_nodate,
	title = {Neural {Algorithmic} {Reasoning} for {Combinatorial} {Optimisation}},
	abstract = {Solving NP-hard/complete combinatorial problems with neural networks is a challenging research area that aims to surpass classical approximate algorithms. The long-term objective is to outperform hand-designed heuristics for NP-hard/complete problems by learning to generate superior solutions solely from training data. Current neural-based methods for solving CO problems often overlook the inherent “algorithmic” nature of the problems. In contrast, heuristics designed for CO problems, e.g. TSP, frequently leverage well-established algorithms, such as those for finding the minimum spanning tree. In this paper, we propose leveraging recent advancements in neural algorithmic reasoning to improve the learning of CO problems. Specifically, we suggest pre-training our neural model on relevant algorithms before training it on CO instances. Our results demonstrate that by using this learning setup, we achieve superior performance compared to non-algorithmically informed deep learning models.},
	language = {en},
	author = {Georgiev, Dobrik and Numeroso, Danilo and Bacciu, Davide and Liò, Pietro},
	keywords = {Important},
	file = {PDF:/Users/terrytong/Zotero/storage/BKQGGJLZ/Georgiev et al. - Neural Algorithmic Reasoning for Combinatorial Optimisation.pdf:application/pdf},
}

@inproceedings{xhonneux_how_2021,
	title = {How to transfer algorithmic reasoning knowledge to learn new algorithms?},
	volume = {34},
	url = {https://proceedings.neurips.cc/paper_files/paper/2021/hash/a2802cade04644083dcde1c8c483ed9a-Abstract.html},
	abstract = {Learning to execute algorithms is a fundamental problem that has been widely studied. Prior work (Veličković et al., 2019) has shown that to enable systematic generalisation on graph algorithms it is critical to have access to the intermediate steps of the program/algorithm. In many reasoning tasks, where algorithmic-style reasoning is important, we only have access to the input and output examples. Thus, inspired by the success of pre-training on similar tasks or data in Natural Language Processing (NLP) and Computer vision, we set out to study how we can transfer algorithmic reasoning knowledge. Specifically, we investigate how we can use algorithms for which we have access to the execution trace to learn to solve similar tasks for which we do not. We investigate two major classes of graph algorithms, parallel algorithms such as breadth-first search and Bellman-Ford and sequential greedy algorithms such as Prims and Dijkstra. Due to the fundamental differences between algorithmic reasoning knowledge and feature extractors such as used in Computer vision or NLP, we hypothesis that standard transfer techniques will not be sufficient to achieve systematic generalisation. To investigate this empirically we create a dataset including 9 algorithms and 3 different graph types. We validate this empirically and show how instead multi-task learning can be used to achieve the transfer of algorithmic reasoning knowledge.},
	urldate = {2025-06-24},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Xhonneux, Louis-Pascal and Deac, Andreea-Ioana and Veličković, Petar and Tang, Jian},
	year = {2021},
	pages = {19500--19512},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/XPMZHSUT/Xhonneux et al. - 2021 - How to transfer algorithmic reasoning knowledge to learn new algorithms.pdf:application/pdf},
}

@misc{he_primal-dual_2025,
	title = {Primal-{Dual} {Neural} {Algorithmic} {Reasoning}},
	url = {http://arxiv.org/abs/2505.24067},
	doi = {10.48550/arXiv.2505.24067},
	abstract = {Neural Algorithmic Reasoning (NAR) trains neural networks to simulate classical algorithms, enabling structured and interpretable reasoning over complex data. While prior research has predominantly focused on learning exact algorithms for polynomial-time-solvable problems, extending NAR to harder problems remains an open challenge. In this work, we introduce a general NAR framework grounded in the primal-dual paradigm, a classical method for designing efficient approximation algorithms. By leveraging a bipartite representation between primal and dual variables, we establish an alignment between primal-dual algorithms and Graph Neural Networks. Furthermore, we incorporate optimal solutions from small instances to greatly enhance the model's reasoning capabilities. Our empirical results demonstrate that our model not only simulates but also outperforms approximation algorithms for multiple tasks, exhibiting robust generalization to larger and out-of-distribution graphs. Moreover, we highlight the framework's practical utility by integrating it with commercial solvers and applying it to real-world datasets.},
	urldate = {2025-06-24},
	publisher = {arXiv},
	author = {He, Yu and Vitercik, Ellen},
	month = may,
	year = {2025},
	note = {arXiv:2505.24067 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: The 42nd International Conference on Machine Learning, 2025},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/NY72QDXT/He and Vitercik - 2025 - Primal-Dual Neural Algorithmic Reasoning.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/I6SMQVHX/2505.html:text/html},
}

@misc{kujawa_neural_2024,
	title = {Neural {Algorithmic} {Reasoning} with {Multiple} {Correct} {Solutions}},
	url = {http://arxiv.org/abs/2409.06953},
	doi = {10.48550/arXiv.2409.06953},
	abstract = {Neural Algorithmic Reasoning (NAR) aims to optimize classical algorithms. However, canonical implementations of NAR train neural networks to return only a single solution, even when there are multiple correct solutions to a problem, such as single-source shortest paths. For some applications, it is desirable to recover more than one correct solution. To that end, we give the first method for NAR with multiple solutions. We demonstrate our method on two classical algorithms: Bellman-Ford (BF) and Depth-First Search (DFS), favouring deeper insight into two algorithms over a broader survey of algorithms. This method involves generating appropriate training data as well as sampling and validating solutions from model output. Each step of our method, which can serve as a framework for neural algorithmic reasoning beyond the tasks presented in this paper, might be of independent interest to the field and our results represent the first attempt at this task in the NAR literature.},
	urldate = {2025-06-24},
	publisher = {arXiv},
	author = {Kujawa, Zeno and Poole, John and Georgiev, Dobrik and Numeroso, Danilo and Liò, Pietro},
	month = sep,
	year = {2024},
	note = {arXiv:2409.06953 [cs]
version: 1},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/Z7SY575L/Kujawa et al. - 2024 - Neural Algorithmic Reasoning with Multiple Correct Solutions.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/J67DSS9C/2409.html:text/html},
}

@inproceedings{ibarz_generalist_2022,
	title = {A {Generalist} {Neural} {Algorithmic} {Learner}},
	url = {https://proceedings.mlr.press/v198/ibarz22a.html},
	abstract = {The cornerstone of neural algorithmic reasoning is the ability to solve algorithmic tasks, especially in a way that generalises out of distribution. While recent years have seen a surge in methodological improvements in this area, they mostly focused on building specialist models. Specialist models are capable of learning to neurally execute either only one algorithm or a collection of algorithms with identical control-flow backbone. Here, instead, we focus on constructing a generalist neural algorithmic learner—a single graph neural network processor capable of learning to execute a wide range of algorithms, such as sorting, searching, dynamic programming, path-finding and geometry. We leverage the CLRS benchmark to empirically show that, much like recent successes in the domain of perception, generalist algorithmic learners can be built by "incorporating" knowledge. That is, it is possible to effectively learn algorithms in a multi-task manner, so long as we can learn to execute them well in a single-task regime. Motivated by this, we present a series of improvements to the input representation, training regime and processor architecture over CLRS, improving average single-task performance by over 20\% from prior art. We then conduct a thorough ablation of multi-task learners leveraging these improvements. Our results demonstrate a generalist learner that effectively incorporates knowledge captured by specialist models.},
	language = {en},
	urldate = {2025-06-24},
	booktitle = {Proceedings of the {First} {Learning} on {Graphs} {Conference}},
	publisher = {PMLR},
	author = {Ibarz, Borja and Kurin, Vitaly and Papamakarios, George and Nikiforou, Kyriacos and Bennani, Mehdi and Csordás, Róbert and Dudzik, Andrew Joseph and Bošnjak, Matko and Vitvitskyi, Alex and Rubanova, Yulia and Deac, Andreea and Bevilacqua, Beatrice and Ganin, Yaroslav and Blundell, Charles and Veličković, Petar},
	month = dec,
	year = {2022},
	note = {ISSN: 2640-3498},
	pages = {2:1--2:23},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/5A27YPLP/Ibarz et al. - 2022 - A Generalist Neural Algorithmic Learner.pdf:application/pdf},
}

@article{li_open-book_nodate,
	title = {Open-{Book} {Neural} {Algorithmic} {Reasoning}},
	abstract = {Neural algorithmic reasoning is an emerging area of machine learning that focuses on building neural networks capable of solving complex algorithmic tasks. Recent advancements predominantly follow the standard supervised learning paradigm –feeding an individual problem instance into the network each time and training it to approximate the execution steps of a classical algorithm. We challenge this mode and propose a novel open-book learning framework. In this framework, whether during training or testing, the network can access and utilize all instances in the training dataset when reasoning for a given instance.},
	language = {en},
	author = {Li, Hefei and Peng, Chao and Xu, Chenyang and Yang, Zhengfeng},
	file = {PDF:/Users/terrytong/Zotero/storage/IXWAXXVU/Li et al. - Open-Book Neural Algorithmic Reasoning.pdf:application/pdf},
}

@misc{yan_neural_2020,
	title = {Neural {Execution} {Engines}: {Learning} to {Execute} {Subroutines}},
	shorttitle = {Neural {Execution} {Engines}},
	url = {http://arxiv.org/abs/2006.08084},
	doi = {10.48550/arXiv.2006.08084},
	abstract = {A significant effort has been made to train neural networks that replicate algorithmic reasoning, but they often fail to learn the abstract concepts underlying these algorithms. This is evidenced by their inability to generalize to data distributions that are outside of their restricted training sets, namely larger inputs and unseen data. We study these generalization issues at the level of numerical subroutines that comprise common algorithms like sorting, shortest paths, and minimum spanning trees. First, we observe that transformer-based sequence-to-sequence models can learn subroutines like sorting a list of numbers, but their performance rapidly degrades as the length of lists grows beyond those found in the training set. We demonstrate that this is due to attention weights that lose fidelity with longer sequences, particularly when the input numbers are numerically similar. To address the issue, we propose a learned conditional masking mechanism, which enables the model to strongly generalize far outside of its training range with near-perfect accuracy on a variety of algorithms. Second, to generalize to unseen data, we show that encoding numbers with a binary representation leads to embeddings with rich structure once trained on downstream tasks like addition or multiplication. This allows the embedding to handle missing data by faithfully interpolating numbers not seen during training.},
	urldate = {2025-06-24},
	publisher = {arXiv},
	author = {Yan, Yujun and Swersky, Kevin and Koutra, Danai and Ranganathan, Parthasarathy and Hashemi, Milad},
	month = oct,
	year = {2020},
	note = {arXiv:2006.08084 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Programming Languages, Important},
	annote = {Comment: Accepted at 34th Conference on Neural Information Processing Systems (NeurIPS 2020)},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/YKGMVHPD/Yan et al. - 2020 - Neural Execution Engines Learning to Execute Subroutines.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/SL2EIKKF/2006.html:text/html},
}


%sempre


@misc{shin_few-shot_2022,
	title = {Few-{Shot} {Semantic} {Parsing} with {Language} {Models} {Trained} {On} {Code}},
	url = {http://arxiv.org/abs/2112.08696},
	doi = {10.48550/arXiv.2112.08696},
	abstract = {Large language models can perform semantic parsing with little training data, when prompted with in-context examples. It has been shown that this can be improved by formulating the problem as paraphrasing into canonical utterances, which casts the underlying meaning representation into a controlled natural language-like representation. Intuitively, such models can more easily output canonical utterances as they are closer to the natural language used for pre-training. Recently, models also pre-trained on code, like OpenAI Codex, have risen in prominence. For semantic parsing tasks where we map natural language into code, such models may prove more adept at it. In this paper, we test this hypothesis and find that Codex performs better on such tasks than equivalent GPT-3 models. We evaluate on Overnight and SMCalFlow and find that unlike GPT-3, Codex performs similarly when targeting meaning representations directly, perhaps because meaning representations are structured similar to code in these datasets.},
	urldate = {2025-06-23},
	publisher = {arXiv},
	author = {Shin, Richard and Durme, Benjamin Van},
	month = may,
	year = {2022},
	note = {arXiv:2112.08696 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: NAACL 2022},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/TFUPACNM/Shin and Durme - 2022 - Few-Shot Semantic Parsing with Language Models Trained On Code.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/J3SNPU73/2112.html:text/html},
}

@inproceedings{krishnamurthy_neural_2017,
	address = {Copenhagen, Denmark},
	title = {Neural {Semantic} {Parsing} with {Type} {Constraints} for {Semi}-{Structured} {Tables}},
	url = {https://aclanthology.org/D17-1160/},
	doi = {10.18653/v1/D17-1160},
	abstract = {We present a new semantic parsing model for answering compositional questions on semi-structured Wikipedia tables. Our parser is an encoder-decoder neural network with two key technical innovations: (1) a grammar for the decoder that only generates well-typed logical forms; and (2) an entity embedding and linking module that identifies entity mentions while generalizing across tables. We also introduce a novel method for training our neural model with question-answer supervision. On the WikiTableQuestions data set, our parser achieves a state-of-the-art accuracy of 43.3\% for a single model and 45.9\% for a 5-model ensemble, improving on the best prior score of 38.7\% set by a 15-model ensemble. These results suggest that type constraints and entity linking are valuable components to incorporate in neural semantic parsers.},
	urldate = {2025-06-23},
	booktitle = {Proceedings of the 2017 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Krishnamurthy, Jayant and Dasigi, Pradeep and Gardner, Matt},
	editor = {Palmer, Martha and Hwa, Rebecca and Riedel, Sebastian},
	month = sep,
	year = {2017},
	pages = {1516--1526},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/YS3X4Q63/Krishnamurthy et al. - 2017 - Neural Semantic Parsing with Type Constraints for Semi-Structured Tables.pdf:application/pdf},
}

@misc{drozdov_compositional_2022,
	title = {Compositional {Semantic} {Parsing} with {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2209.15003},
	doi = {10.48550/arXiv.2209.15003},
	abstract = {Humans can reason compositionally when presented with new tasks. Previous research shows that appropriate prompting techniques enable large language models (LLMs) to solve artificial compositional generalization tasks such as SCAN. In this work, we identify additional challenges in more realistic semantic parsing tasks with larger vocabulary and refine these prompting techniques to address them. Our best method is based on least-to-most prompting: it decomposes the problem using prompting-based syntactic parsing, then uses this decomposition to select appropriate exemplars and to sequentially generate the semantic parse. This method allows us to set a new state of the art for CFQ while requiring only 1\% of the training data used by traditional approaches. Due to the general nature of our approach, we expect similar efforts will lead to new results in other tasks and domains, especially for knowledge-intensive applications.},
	urldate = {2025-06-24},
	publisher = {arXiv},
	author = {Drozdov, Andrew and Schärli, Nathanael and Akyürek, Ekin and Scales, Nathan and Song, Xinying and Chen, Xinyun and Bousquet, Olivier and Zhou, Denny},
	month = sep,
	year = {2022},
	note = {arXiv:2209.15003 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	annote = {Comment: Fixed metadata. No other changes},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/Q8CJYY8V/Drozdov et al. - 2022 - Compositional Semantic Parsing with Large Language Models.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/53ACFNZ3/2209.html:text/html},
}

@misc{mannekote_towards_2024,
	title = {Towards {Compositionally} {Generalizable} {Semantic} {Parsing} in {Large} {Language} {Models}: {A} {Survey}},
	shorttitle = {Towards {Compositionally} {Generalizable} {Semantic} {Parsing} in {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2404.13074},
	doi = {10.48550/arXiv.2404.13074},
	abstract = {Compositional generalization is the ability of a model to generalize to complex, previously unseen types of combinations of entities from just having seen the primitives. This type of generalization is particularly relevant to the semantic parsing community for applications such as task-oriented dialogue, text-to-SQL parsing, and information retrieval, as they can harbor infinite complexity. Despite the success of large language models (LLMs) in a wide range of NLP tasks, unlocking perfect compositional generalization still remains one of the few last unsolved frontiers. The past few years has seen a surge of interest in works that explore the limitations of, methods to improve, and evaluation metrics for compositional generalization capabilities of LLMs for semantic parsing tasks. In this work, we present a literature survey geared at synthesizing recent advances in analysis, methods, and evaluation schemes to offer a starting point for both practitioners and researchers in this area.},
	urldate = {2025-06-24},
	publisher = {arXiv},
	author = {Mannekote, Amogh},
	month = apr,
	year = {2024},
	note = {arXiv:2404.13074 [cs]
version: 1},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/4YNEEB5E/Mannekote - 2024 - Towards Compositionally Generalizable Semantic Parsing in Large Language Models A Survey.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/39WMJM4W/2404.html:text/html},
}

@inproceedings{berant_semantic_2013,
	address = {Seattle, Washington, USA},
	title = {Semantic {Parsing} on {Freebase} from {Question}-{Answer} {Pairs}},
	url = {https://aclanthology.org/D13-1160/},
	urldate = {2025-08-01},
	booktitle = {Proceedings of the 2013 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Berant, Jonathan and Chou, Andrew and Frostig, Roy and Liang, Percy},
	editor = {Yarowsky, David and Baldwin, Timothy and Korhonen, Anna and Livescu, Karen and Bethard, Steven},
	month = oct,
	year = {2013},
	pages = {1533--1544},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/ZW6ABUL4/Berant et al. - 2013 - Semantic Parsing on Freebase from Question-Answer Pairs.pdf:application/pdf},
}

@misc{dong_language_2016,
	title = {Language to {Logical} {Form} with {Neural} {Attention}},
	url = {http://arxiv.org/abs/1601.01280},
	doi = {10.48550/arXiv.1601.01280},
	abstract = {Semantic parsing aims at mapping natural language to machine interpretable meaning representations. Traditional approaches rely on high-quality lexicons, manually-built templates, and linguistic features which are either domain- or representation-specific. In this paper we present a general method based on an attention-enhanced encoder-decoder model. We encode input utterances into vector representations, and generate their logical forms by conditioning the output sequences or trees on the encoding vectors. Experimental results on four datasets show that our approach performs competitively without using hand-engineered features and is easy to adapt across domains and meaning representations.},
	urldate = {2025-08-01},
	publisher = {arXiv},
	author = {Dong, Li and Lapata, Mirella},
	month = jun,
	year = {2016},
	note = {arXiv:1601.01280 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted by ACL-16},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/H9GBPPGL/Dong and Lapata - 2016 - Language to Logical Form with Neural Attention.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/6CLPX28X/1601.html:text/html},
}

@misc{dong_coarse--fine_2018,
	title = {Coarse-to-{Fine} {Decoding} for {Neural} {Semantic} {Parsing}},
	url = {http://arxiv.org/abs/1805.04793},
	doi = {10.48550/arXiv.1805.04793},
	abstract = {Semantic parsing aims at mapping natural language utterances into structured meaning representations. In this work, we propose a structure-aware neural architecture which decomposes the semantic parsing process into two stages. Given an input utterance, we first generate a rough sketch of its meaning, where low-level information (such as variable names and arguments) is glossed over. Then, we fill in missing details by taking into account the natural language input and the sketch itself. Experimental results on four datasets characteristic of different domains and meaning representations show that our approach consistently improves performance, achieving competitive results despite the use of relatively simple decoders.},
	urldate = {2025-08-01},
	publisher = {arXiv},
	author = {Dong, Li and Lapata, Mirella},
	month = may,
	year = {2018},
	note = {arXiv:1805.04793 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted by ACL-18},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/XNYGU8BT/Dong and Lapata - 2018 - Coarse-to-Fine Decoding for Neural Semantic Parsing.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/W4H6PBBU/1805.html:text/html},
}

@misc{rabinovich_abstract_2017,
	title = {Abstract {Syntax} {Networks} for {Code} {Generation} and {Semantic} {Parsing}},
	url = {http://arxiv.org/abs/1704.07535},
	doi = {10.48550/arXiv.1704.07535},
	abstract = {Tasks like code generation and semantic parsing require mapping unstructured (or partially structured) inputs to well-formed, executable outputs. We introduce abstract syntax networks, a modeling framework for these problems. The outputs are represented as abstract syntax trees (ASTs) and constructed by a decoder with a dynamically-determined modular structure paralleling the structure of the output tree. On the benchmark Hearthstone dataset for code generation, our model obtains 79.2 BLEU and 22.7\% exact match accuracy, compared to previous state-of-the-art values of 67.1 and 6.1\%. Furthermore, we perform competitively on the Atis, Jobs, and Geo semantic parsing datasets with no task-specific engineering.},
	urldate = {2025-08-01},
	publisher = {arXiv},
	author = {Rabinovich, Maxim and Stern, Mitchell and Klein, Dan},
	month = apr,
	year = {2017},
	note = {arXiv:1704.07535 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	annote = {Comment: ACL 2017. MR and MS contributed equally},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/5FGU66IM/Rabinovich et al. - 2017 - Abstract Syntax Networks for Code Generation and Semantic Parsing.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/N2XMJ9AD/1704.html:text/html},
}

@inproceedings{misra_neural_2016,
	address = {Austin, Texas},
	title = {Neural {Shift}-{Reduce} {CCG} {Semantic} {Parsing}},
	url = {http://aclweb.org/anthology/D16-1183},
	doi = {10.18653/v1/D16-1183},
	abstract = {We present a shift-reduce CCG semantic parser. Our parser uses a neural network architecture that balances model capacity and computational cost. We train by transferring a model from a computationally expensive loglinear CKY parser. Our learner addresses two challenges: selecting the best parse for learning when the CKY parser generates multiple correct trees, and learning from partial derivations when the CKY parser fails to parse. We evaluate on AMR parsing. Our parser performs comparably to the CKY parser, while doing signiﬁcantly fewer operations. We also present results for greedy semantic parsing with a relatively small drop in performance.},
	language = {en},
	urldate = {2025-08-06},
	booktitle = {Proceedings of the 2016 {Conference} on {Empirical} {Methods} in {Natural}           {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Misra, Dipendra Kumar and Artzi, Yoav},
	year = {2016},
	pages = {1775--1786},
	file = {PDF:/Users/terrytong/Zotero/storage/WFDCZGGI/Misra and Artzi - 2016 - Neural Shift-Reduce CCG Semantic Parsing.pdf:application/pdf},
}

@article{krishnamurthy_vector_nodate,
	title = {Vector {Space} {Semantic} {Parsing}: {A} {Framework} for {Compositional} {Vector} {Space} {Models}},
	abstract = {We present vector space semantic parsing (VSSP), a framework for learning compositional models of vector space semantics. Our framework uses Combinatory Categorial Grammar (CCG) to deﬁne a correspondence between syntactic categories and semantic representations, which are vectors and functions on vectors. The complete correspondence is a direct consequence of minimal assumptions about the semantic representations of basic syntactic categories (e.g., nouns are vectors), and CCG’s tight coupling of syntax and semantics. Furthermore, this correspondence permits nonuniform semantic representations and more expressive composition operations than previous work. VSSP builds a CCG semantic parser respecting this correspondence; this semantic parser parses text into lambda calculus formulas that evaluate to vector space representations. In these formulas, the meanings of words are represented by parameters that can be trained in a task-speciﬁc fashion. We present experiments using noun-verbnoun and adverb-adjective-noun phrases which demonstrate that VSSP can learn composition operations that RNN (Socher et al., 2011) and MV-RNN (Socher et al., 2012) cannot.},
	language = {en},
	author = {Krishnamurthy, Jayant and Mitchell, Tom},
	file = {PDF:/Users/terrytong/Zotero/storage/XDUGFP2G/Krishnamurthy and Mitchell - Vector Space Semantic Parsing A Framework for Compositional Vector Space Models.pdf:application/pdf},
}


%reasoning
@misc{zelikman_star_2022,
	title = {{STaR}: {Bootstrapping} {Reasoning} {With} {Reasoning}},
	shorttitle = {{STaR}},
	url = {http://arxiv.org/abs/2203.14465},
	doi = {10.48550/arXiv.2203.14465},
	abstract = {Generating step-by-step "chain-of-thought" rationales improves language model performance on complex reasoning tasks like mathematics or commonsense question-answering. However, inducing language model rationale generation currently requires either constructing massive rationale datasets or sacrificing accuracy by using only few-shot inference. We propose a technique to iteratively leverage a small number of rationale examples and a large dataset without rationales, to bootstrap the ability to perform successively more complex reasoning. This technique, the "Self-Taught Reasoner" (STaR), relies on a simple loop: generate rationales to answer many questions, prompted with a few rationale examples; if the generated answers are wrong, try again to generate a rationale given the correct answer; fine-tune on all the rationales that ultimately yielded correct answers; repeat. We show that STaR significantly improves performance on multiple datasets compared to a model fine-tuned to directly predict final answers, and performs comparably to fine-tuning a 30\${\textbackslash}times\$ larger state-of-the-art language model on CommensenseQA. Thus, STaR lets a model improve itself by learning from its own generated reasoning.},
	urldate = {2025-06-16},
	publisher = {arXiv},
	author = {Zelikman, Eric and Wu, Yuhuai and Mu, Jesse and Goodman, Noah D.},
	month = may,
	year = {2022},
	note = {arXiv:2203.14465 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/ZXYTPEAP/Zelikman et al. - 2022 - STaR Bootstrapping Reasoning With Reasoning.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/D5DPEJQN/2203.html:text/html},
}

@misc{marra_integrating_2019,
	title = {Integrating {Learning} and {Reasoning} with {Deep} {Logic} {Models}},
	url = {http://arxiv.org/abs/1901.04195},
	doi = {10.48550/arXiv.1901.04195},
	abstract = {Deep learning is very effective at jointly learning feature representations and classification models, especially when dealing with high dimensional input patterns. Probabilistic logic reasoning, on the other hand, is capable to take consistent and robust decisions in complex environments. The integration of deep learning and logic reasoning is still an open-research problem and it is considered to be the key for the development of real intelligent agents. This paper presents Deep Logic Models, which are deep graphical models integrating deep learning and logic reasoning both for learning and inference. Deep Logic Models create an end-to-end differentiable architecture, where deep learners are embedded into a network implementing a continuous relaxation of the logic knowledge. The learning process allows to jointly learn the weights of the deep learners and the meta-parameters controlling the high-level reasoning. The experimental results show that the proposed methodology overtakes the limitations of the other approaches that have been proposed to bridge deep learning and reasoning.},
	urldate = {2025-06-23},
	publisher = {arXiv},
	author = {Marra, Giuseppe and Giannini, Francesco and Diligenti, Michelangelo and Gori, Marco},
	month = jan,
	year = {2019},
	note = {arXiv:1901.04195 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/9R5WLG3W/Marra et al. - 2019 - Integrating Learning and Reasoning with Deep Logic Models.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/3R2UXM37/1901.html:text/html},
}

@inproceedings{olausson_linc_2023,
	title = {{LINC}: {A} {Neurosymbolic} {Approach} for {Logical} {Reasoning} by {Combining} {Language} {Models} with {First}-{Order} {Logic} {Provers}},
	shorttitle = {{LINC}},
	url = {http://arxiv.org/abs/2310.15164},
	doi = {10.18653/v1/2023.emnlp-main.313},
	abstract = {Logical reasoning, i.e., deductively inferring the truth value of a conclusion from a set of premises, is an important task for artificial intelligence with wide potential impacts on science, mathematics, and society. While many prompting-based strategies have been proposed to enable Large Language Models (LLMs) to do such reasoning more effectively, they still appear unsatisfactory, often failing in subtle and unpredictable ways. In this work, we investigate the validity of instead reformulating such tasks as modular neurosymbolic programming, which we call LINC: Logical Inference via Neurosymbolic Computation. In LINC, the LLM acts as a semantic parser, translating premises and conclusions from natural language to expressions in first-order logic. These expressions are then offloaded to an external theorem prover, which symbolically performs deductive inference. Leveraging this approach, we observe significant performance gains on FOLIO and a balanced subset of ProofWriter for three different models in nearly all experimental conditions we evaluate. On ProofWriter, augmenting the comparatively small open-source StarCoder+ (15.5B parameters) with LINC even outperforms GPT-3.5 and GPT-4 with Chain-of-Thought (CoT) prompting by an absolute 38\% and 10\%, respectively. When used with GPT-4, LINC scores 26\% higher than CoT on ProofWriter while performing comparatively on FOLIO. Further analysis reveals that although both methods on average succeed roughly equally often on this dataset, they exhibit distinct and complementary failure modes. We thus provide promising evidence for how logical reasoning over natural language can be tackled through jointly leveraging LLMs alongside symbolic provers. All corresponding code is publicly available at https://github.com/benlipkin/linc},
	urldate = {2025-06-25},
	booktitle = {Proceedings of the 2023 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	author = {Olausson, Theo X. and Gu, Alex and Lipkin, Benjamin and Zhang, Cedegao E. and Solar-Lezama, Armando and Tenenbaum, Joshua B. and Levy, Roger},
	year = {2023},
	note = {arXiv:2310.15164 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Important},
	pages = {5153--5176},
	annote = {Comment: EMNLP Main 2023 (Outstanding Paper Award)},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/4FXKYDG3/Olausson et al. - 2023 - LINC A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order L.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/UBJRBPE3/2310.html:text/html},
}

@misc{han_folio_2024,
	title = {{FOLIO}: {Natural} {Language} {Reasoning} with {First}-{Order} {Logic}},
	shorttitle = {{FOLIO}},
	url = {http://arxiv.org/abs/2209.00840},
	doi = {10.48550/arXiv.2209.00840},
	abstract = {Large language models (LLMs) have achieved remarkable performance on a variety of natural language understanding tasks. However, existing benchmarks are inadequate in measuring the complex logical reasoning capabilities of a model. We present FOLIO, a human-annotated, logically complex and diverse dataset for reasoning in natural language (NL), equipped with first-order logic (FOL) annotations. FOLIO consists of 1,430 examples (unique conclusions), each paired with one of 487 sets of premises used to deductively reason for the validity of each conclusion. The logical correctness of the premises and conclusions is ensured by their FOL annotations, which are automatically verified by an FOL inference engine. In addition to the main NL reasoning task, NL-FOL pairs in FOLIO constitute a new NL-FOL translation dataset. Our experiments on FOLIO systematically evaluate the FOL reasoning ability of supervised fine-tuning on medium-sized language models. For both NL reasoning and NL-FOL translation, we benchmark multiple state-of-the-art language models. Our results show that a subset of FOLIO presents a challenge for one of the most capable \{Large Language Model (LLM)\} publicly available, GPT-4.},
	urldate = {2025-06-27},
	publisher = {arXiv},
	author = {Han, Simeng and Schoelkopf, Hailey and Zhao, Yilun and Qi, Zhenting and Riddell, Martin and Zhou, Wenfei and Coady, James and Peng, David and Qiao, Yujie and Benson, Luke and Sun, Lucy and Wardle-Solano, Alex and Szabo, Hannah and Zubova, Ekaterina and Burtell, Matthew and Fan, Jonathan and Liu, Yixin and Wong, Brian and Sailor, Malcolm and Ni, Ansong and Nan, Linyong and Kasai, Jungo and Yu, Tao and Zhang, Rui and Fabbri, Alexander R. and Kryscinski, Wojciech and Yavuz, Semih and Liu, Ye and Lin, Xi Victoria and Joty, Shafiq and Zhou, Yingbo and Xiong, Caiming and Ying, Rex and Cohan, Arman and Radev, Dragomir},
	month = oct,
	year = {2024},
	note = {arXiv:2209.00840 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/CV5RPSSP/Han et al. - 2024 - FOLIO Natural Language Reasoning with First-Order Logic.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/49WRF5IC/2209.html:text/html},
}

@misc{merrill_expressive_2024,
	title = {The {Expressive} {Power} of {Transformers} with {Chain} of {Thought}},
	url = {http://arxiv.org/abs/2310.07923},
	doi = {10.48550/arXiv.2310.07923},
	abstract = {Recent theoretical work has identified surprisingly simple reasoning problems, such as checking if two nodes in a graph are connected or simulating finite-state machines, that are provably unsolvable by standard transformers that answer immediately after reading their input. However, in practice, transformers' reasoning can be improved by allowing them to use a "chain of thought" or "scratchpad", i.e., generate and condition on a sequence of intermediate tokens before answering. Motivated by this, we ask: Does such intermediate generation fundamentally extend the computational power of a decoder-only transformer? We show that the answer is yes, but the amount of increase depends crucially on the amount of intermediate generation. For instance, we find that transformer decoders with a logarithmic number of decoding steps (w.r.t. the input length) push the limits of standard transformers only slightly, while a linear number of decoding steps, assuming projected pre-norm (a slight generalization of standard pre-norm), adds a clear new ability (under standard complexity conjectures): recognizing all regular languages. Our results also imply that linear steps keep transformer decoders within context-sensitive languages, and polynomial steps with generalized pre-norm make them recognize exactly the class of polynomial-time solvable problems -- the first exact characterization of a type of transformers in terms of standard complexity classes. Together, this provides a nuanced framework for understanding how the length of a transformer's chain of thought or scratchpad impacts its reasoning power.},
	urldate = {2025-07-02},
	publisher = {arXiv},
	author = {Merrill, William and Sabharwal, Ashish},
	month = apr,
	year = {2024},
	note = {arXiv:2310.07923 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Logic in Computer Science, Computer Science - Computational Complexity, Important1},
	annote = {Comment: 9-page preprint. ICLR camera ready posted April 11},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/92TWL68X/Merrill and Sabharwal - 2024 - The Expressive Power of Transformers with Chain of Thought.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/WFS9KXWV/2310.html:text/html},
}

@article{feng_towards_nodate,
	title = {Towards {Revealing} the {Mystery} behind {Chain} of {Thought}: {A} {Theoretical} {Perspective}},
	abstract = {Recent studies have discovered that Chain-of-Thought prompting (CoT) can dramatically improve the performance of Large Language Models (LLMs), particularly when dealing with complex tasks involving mathematics or reasoning. Despite the enormous empirical success, the underlying mechanisms behind CoT and how it unlocks the potential of LLMs remain elusive. In this paper, we take a first step towards theoretically answering these questions. Specifically, we examine the expressivity of LLMs with CoT in solving fundamental mathematical and decisionmaking problems. By using circuit complexity theory, we first give impossibility results showing that bounded-depth Transformers are unable to directly produce correct answers for basic arithmetic/equation tasks unless the model size grows super-polynomially with respect to the input length. In contrast, we then prove by construction that autoregressive Transformers of constant size suffice to solve both tasks by generating CoT derivations using a commonly used math language format. Moreover, we show LLMs with CoT can handle a general class of decision-making problems known as Dynamic Programming, thus justifying their power in tackling complex real-world tasks. Finally, an extensive set of experiments show that, while Transformers always fail to directly predict the answers, they can consistently learn to generate correct solutions step-by-step given sufficient CoT demonstrations.},
	language = {en},
	author = {Feng, Guhao and Zhang, Bohang and Gu, Yuntian and Ye, Haotian and He, Di and Wang, Liwei},
	keywords = {Important1},
	file = {PDF:/Users/terrytong/Zotero/storage/5LX2IVSM/Feng et al. - Towards Revealing the Mystery behind Chain of Thought A Theoretical Perspective.pdf:application/pdf},
}

@article{merrill_logic_nodate,
	title = {A {Logic} for {Expressing} {Log}-{Precision} {Transformers}},
	abstract = {One way to interpret the reasoning power of transformer-based language models is to describe the types of logical rules they can resolve over some input text. Recently, Chiang et al. (2023) showed that ﬁnite-precision transformer classiﬁers can be equivalently expressed in a generalization of ﬁrst-order logic. However, ﬁnite-precision transformers are a weak transformer variant because, as we show, a single head can only attend to a constant number of tokens and, in particular, cannot represent uniform attention. Since attending broadly is a core capability for transformers, we ask whether a minimally more expressive model that can attend universally can also be characterized in logic. To this end, we analyze transformers whose forward pass is computed in log n precision on contexts of length n. We prove any log-precision transformer classiﬁer can be equivalently expressed as a ﬁrst-order logic sentence that, in addition to standard universal and existential quantiﬁers, may also contain majority-vote quantiﬁers. This is the tightest known upper bound and ﬁrst logical characterization of log-precision transformers.},
	language = {en},
	author = {Merrill, William and Sabharwal, Ashish},
	file = {PDF:/Users/terrytong/Zotero/storage/56S2VPFA/Merrill and Sabharwal - A Logic for Expressing Log-Precision Transformers.pdf:application/pdf},
}

@misc{altabaa_cot_2025,
	title = {{CoT} {Information}: {Improved} {Sample} {Complexity} under {Chain}-of-{Thought} {Supervision}},
	shorttitle = {{CoT} {Information}},
	url = {http://arxiv.org/abs/2505.15927},
	doi = {10.48550/arXiv.2505.15927},
	abstract = {Learning complex functions that involve multi-step reasoning poses a significant challenge for standard supervised learning from input-output examples. Chain-of-thought (CoT) supervision, which provides intermediate reasoning steps together with the final output, has emerged as a powerful empirical technique, underpinning much of the recent progress in the reasoning capabilities of large language models. This paper develops a statistical theory of learning under CoT supervision. A key characteristic of the CoT setting, in contrast to standard supervision, is the mismatch between the training objective (CoT risk) and the test objective (end-to-end risk). A central part of our analysis, distinguished from prior work, is explicitly linking those two types of risk to achieve sharper sample complexity bounds. This is achieved via the *CoT information measure* \${\textbackslash}mathcal\{I\}\_\{{\textbackslash}mathcal\{D\}, h\_{\textbackslash}star\}{\textasciicircum}\{{\textbackslash}mathrm\{CoT\}\}({\textbackslash}epsilon; {\textbackslash}calH)\$, which quantifies the additional discriminative power gained from observing the reasoning process. The main theoretical results demonstrate how CoT supervision can yield significantly faster learning rates compared to standard E2E supervision. Specifically, it is shown that the sample complexity required to achieve a target E2E error \${\textbackslash}epsilon\$ scales as \$d/{\textbackslash}mathcal\{I\}\_\{{\textbackslash}mathcal\{D\}, h\_{\textbackslash}star\}{\textasciicircum}\{{\textbackslash}mathrm\{CoT\}\}({\textbackslash}epsilon; {\textbackslash}calH)\$, where \$d\$ is a measure of hypothesis class complexity, which can be much faster than standard \$d/{\textbackslash}epsilon\$ rates. Information-theoretic lower bounds in terms of the CoT information are also obtained. Together, these results suggest that CoT information is a fundamental measure of statistical complexity for learning under chain-of-thought supervision.},
	urldate = {2025-07-28},
	publisher = {arXiv},
	author = {Altabaa, Awni and Montasser, Omar and Lafferty, John},
	month = may,
	year = {2025},
	note = {arXiv:2505.15927 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/YSI9TK72/Altabaa et al. - 2025 - CoT Information Improved Sample Complexity under Chain-of-Thought Supervision.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/66SR55AP/2505.html:text/html},
}

@article{liang_chain--thought_nodate,
	title = {Chain-of-{Thought} {Reasoning} for {Math}: {Theoretical} {Foundation}  and {Applications}},
	abstract = {Chain-of-Thought (CoT) prompting improves the reasoning capabilities of large language models (LLMs), but its theoretical basis remains poorly understood. We propose an information-theoretic framework to analyze and improve CoT through two complementary lenses. First, we model CoT as a Markov process X → Z → Y , where intermediate steps Z mediate information from inputs X to outputs Y . By applying the Data Processing Inequality and Fano’s inequality, we show that explicit reasoning lowers the bound on prediction error. Second, we use Partial Information Decomposition (PID) to quantify how CoT rationales contribute to task performance. Our analysis reveals strong synergy, i.e., reasoning and answers together, provide more information than either alone. Building on this insight, we introduce a PID-guided loss that promotes synergy during CoT distillation. On the e-SNLI dataset, this approach outperforms standard fine-tuning and mutual information baselines. To validate CoT’s benefits in structured domains, we also study fewshot arithmetic reasoning. CoT prompting boosts accuracy from 4\% to 70\% with just one example and up to 90\% with four, far surpassing regular prompting. Overall, our findings offer a theoretical foundation for CoT and suggest new strategies for improving reasoning in LLMs.},
	language = {en},
	author = {Liang, Jessica E},
	file = {PDF:/Users/terrytong/Zotero/storage/3596AD83/Liang - Chain-of-Thought Reasoning for Math Theoretical Foundation  and Applications.pdf:application/pdf},
}

@article{garg2022can,
  title={What can transformers learn in-context? a case study of simple function classes},
  author={Garg, Shivam and Tsipras, Dimitris and Liang, Percy S and Valiant, Gregory},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={30583--30598},
  year={2022}
}

@article{akyurek2022learning,
  title={What learning algorithm is in-context learning? investigations with linear models},
  author={Aky{\"u}rek, Ekin and Schuurmans, Dale and Andreas, Jacob and Ma, Tengyu and Zhou, Denny},
  journal={arXiv preprint arXiv:2211.15661},
  year={2022}
}

@article{zhang2024trained,
  title={Trained transformers learn linear models in-context},
  author={Zhang, Ruiqi and Frei, Spencer and Bartlett, Peter L},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={49},
  pages={1--55},
  year={2024}
}

%tool


@misc{parisi_talm_2022,
	title = {{TALM}: {Tool} {Augmented} {Language} {Models}},
	shorttitle = {{TALM}},
	url = {http://arxiv.org/abs/2205.12255},
	doi = {10.48550/arXiv.2205.12255},
	abstract = {Transformer based language models (LMs) demonstrate increasing performance with scale across a wide variety of tasks. Scale alone however cannot enable models to solve tasks that require access to ephemeral, changing, or private data that was unavailable at training time. Many useful tasks may also benefit from LMs being able to access APIs that read or modify state. In this work, we present Tool Augmented Language Models (TALM), combining a text-only approach to augment language models with non-differentiable tools, and an iterative "self-play" technique to bootstrap performance starting from few tool demonstrations. TALM exhibits strong performance on both a knowledge-heavy QA task and a reasoning oriented math task with simple tools. At a given model scale, TALM significantly outperforms non-augmented LMs. We further demonstrate that TALM successfully performs out-of-distribution inferences on both QA and math tasks, where non-augmented LMs fail. Our results suggest that Tool Augmented Language Models are a promising direction to enrich LMs' capabilities, with less dependence on scale.},
	urldate = {2025-06-19},
	publisher = {arXiv},
	author = {Parisi, Aaron and Zhao, Yao and Fiedel, Noah},
	month = may,
	year = {2022},
	note = {arXiv:2205.12255 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/7HLY8E56/Parisi et al. - 2022 - TALM Tool Augmented Language Models.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/TRYGG9AD/2205.html:text/html},
}

@misc{tang_toolalpaca_2023,
	title = {{ToolAlpaca}: {Generalized} {Tool} {Learning} for {Language} {Models} with 3000 {Simulated} {Cases}},
	shorttitle = {{ToolAlpaca}},
	url = {http://arxiv.org/abs/2306.05301},
	doi = {10.48550/arXiv.2306.05301},
	abstract = {Enabling large language models to utilize real-world tools effectively is crucial for achieving embodied intelligence. Existing approaches to tool learning have either primarily relied on extremely large language models, such as GPT-4, to attain generalized tool-use abilities in a zero-shot manner, or utilized supervised learning to train limited scopes of tools on compact models. However, it remains uncertain whether smaller language models can achieve generalized tool-use abilities without tool-specific training. To address this question, this paper introduces ToolAlpaca, a novel framework designed to automatically generate a diverse tool-use corpus and learn generalized tool-use abilities on compact language models with minimal human intervention. Specifically, ToolAlpaca first automatically creates a highly diversified tool-use corpus by building a multi-agent simulation environment. The corpus contains 3938 tool-use instances from more than 400 real-world tool APIs spanning 50 distinct categories. Subsequently, the constructed corpus is employed to fine-tune compact language models, resulting in two models, namely ToolAlpaca-7B and ToolAlpaca-13B, respectively. Finally, we evaluate the ability of these models to utilize previously unseen tools without specific training. Experimental results demonstrate that ToolAlpaca achieves effective generalized tool-use capabilities comparable to those of extremely large language models like GPT-3.5, demonstrating that learning generalized tool-use ability is feasible for compact language models.},
	urldate = {2025-06-19},
	publisher = {arXiv},
	author = {Tang, Qiaoyu and Deng, Ziliang and Lin, Hongyu and Han, Xianpei and Liang, Qiao and Cao, Boxi and Sun, Le},
	month = sep,
	year = {2023},
	note = {arXiv:2306.05301 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/9459S5VY/Tang et al. - 2023 - ToolAlpaca Generalized Tool Learning for Language Models with 3000 Simulated Cases.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/S978UIJI/2306.html:text/html},
}

@misc{qin_toolllm_2023,
	title = {{ToolLLM}: {Facilitating} {Large} {Language} {Models} to {Master} 16000+ {Real}-world {APIs}},
	shorttitle = {{ToolLLM}},
	url = {http://arxiv.org/abs/2307.16789},
	doi = {10.48550/arXiv.2307.16789},
	abstract = {Despite the advancements of open-source large language models (LLMs), e.g., LLaMA, they remain significantly limited in tool-use capabilities, i.e., using external tools (APIs) to fulfill human instructions. The reason is that current instruction tuning largely focuses on basic language tasks but ignores the tool-use domain. This is in contrast to the excellent tool-use capabilities of state-of-the-art (SOTA) closed-source LLMs, e.g., ChatGPT. To bridge this gap, we introduce ToolLLM, a general tool-use framework encompassing data construction, model training, and evaluation. We first present ToolBench, an instruction-tuning dataset for tool use, which is constructed automatically using ChatGPT. Specifically, the construction can be divided into three stages: (i) API collection: we collect 16,464 real-world RESTful APIs spanning 49 categories from RapidAPI Hub; (ii) instruction generation: we prompt ChatGPT to generate diverse instructions involving these APIs, covering both single-tool and multi-tool scenarios; (iii) solution path annotation: we use ChatGPT to search for a valid solution path (chain of API calls) for each instruction. To enhance the reasoning capabilities of LLMs, we develop a novel depth-first search-based decision tree algorithm. It enables LLMs to evaluate multiple reasoning traces and expand the search space. Moreover, to evaluate the tool-use capabilities of LLMs, we develop an automatic evaluator: ToolEval. Based on ToolBench, we fine-tune LLaMA to obtain an LLM ToolLLaMA, and equip it with a neural API retriever to recommend appropriate APIs for each instruction. Experiments show that ToolLLaMA demonstrates a remarkable ability to execute complex instructions and generalize to unseen APIs, and exhibits comparable performance to ChatGPT. Our ToolLLaMA also demonstrates strong zero-shot generalization ability in an out-of-distribution tool-use dataset: APIBench.},
	urldate = {2025-06-19},
	publisher = {arXiv},
	author = {Qin, Yujia and Liang, Shihao and Ye, Yining and Zhu, Kunlun and Yan, Lan and Lu, Yaxi and Lin, Yankai and Cong, Xin and Tang, Xiangru and Qian, Bill and Zhao, Sihan and Hong, Lauren and Tian, Runchu and Xie, Ruobing and Zhou, Jie and Gerstein, Mark and Li, Dahai and Liu, Zhiyuan and Sun, Maosong},
	month = oct,
	year = {2023},
	note = {arXiv:2307.16789 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/GIC4ERW8/Qin et al. - 2023 - ToolLLM Facilitating Large Language Models to Master 16000+ Real-world APIs.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/CS4G7J8T/2307.html:text/html},
}

@article{qin_tool_nodate,
	title = {Tool {Learning} with {Foundation} {Models}},
	abstract = {Humans possess an extraordinary ability to create and utilize tools, allowing them to overcome physical limitations and explore new frontiers. With the advent of recent powerful foundation models, artificial intelligence systems have the potential to be equally adept in tool use as humans. This paradigm, which is dubbed as tool learning with foundation models, combines the strengths of specialized tools and foundation models to achieve enhanced accuracy, efficiency, and automation in problem-solving. Despite its immense potential, there is still a lack of a comprehensive understanding of key challenges, opportunities, and future endeavors in this field. To this end, we present a systematic investigation and comprehensive review of tool learning in this paper. We first introduce the background of tool learning, including its cognitive origins, the paradigm shift of foundation models, and the complementary roles of tools and models. We recapitulate existing tool learning research and formulate a general tool learning framework: starting from understanding the user instruction, models should learn to decompose a complex task into several subtasks, dynamically adjust their plan through reasoning, and effectively conquer each sub-task by selecting appropriate tools. We also discuss how to train models for improved tool-use capabilities and facilitate the generalization in tool learning. Considering the lack of a systematic tool learning evaluation in prior works, we experiment with 18 representative tools and show the potential of current foundation models in skillfully utilizing tools. Finally, we discuss several open problems that require further investigation for tool learning, such as ensuring safe and trustworthy tool use, enabling tool creation with foundation models, and addressing personalization challenges. Overall, we hope this paper could inspire future research in integrating tools with foundation models. Relevant codes and datasets are publicly available for further research exploration1.},
	language = {en},
	author = {Qin, Yujia and Hu, Shengding and Lin, Yankai and Chen, Weize and Ding, Ning and Cui, Ganqu and Zeng, Zheni and Zhou, Xuanhe and Huang, Yufei and Xiao, Chaojun and Han, Chi and Fung, Yi Ren and Su, Yusheng and Wang, Huadong and Qian, Cheng and Tian, Runchu and Zhu, Kunlun and Liang, Shihao and Shen, Xingyu and Xu, Bokai and Zhang, Zhen and Ye, Yining and Li, Bowen and Tang, Ziwei and Yi, Jing and Zhu, Yuzhang and Dai, Zhenning and Yan, Lan and Cong, Xin and Lu, Yaxi and Zhao, Weilin and Huang, Yuxiang and Yan, Junxi and Han, Xu and Sun, Xian and Li, Dahai and Phang, Jason and Yang, Cheng and Wu, Tongshuang and Ji, Heng and Li, Guoliang and Liu, Zhiyuan and Sun, Maosong},
	file = {PDF:/Users/terrytong/Zotero/storage/6JUQ2YIA/Qin et al. - Tool Learning with Foundation Models.pdf:application/pdf},
}

@article{schick_toolformer_nodate,
	title = {Toolformer: {Language} {Models} {Can} {Teach} {Themselves} to {Use} {Tools}},
	abstract = {Language models (LMs) exhibit remarkable abilities to solve new tasks from just a few examples or textual instructions, especially at scale. They also, paradoxically, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller models excel. In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds. We introduce Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction. This is done in a self-supervised way, requiring nothing more than a handful of demonstrations for each API. We incorporate a range of tools, including a calculator, a Q\&A system, a search engine, a translation system, and a calendar. Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacriﬁcing its core language modeling abilities.},
	language = {en},
	author = {Schick, Timo and Dessì, Jane Dwivedi-Yu Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
	file = {PDF:/Users/terrytong/Zotero/storage/FB9XTTEX/Schick et al. - Toolformer Language Models Can Teach Themselves to Use Tools.pdf:application/pdf},
}

@misc{shen_llm_2024,
	title = {{LLM} {With} {Tools}: {A} {Survey}},
	shorttitle = {{LLM} {With} {Tools}},
	url = {http://arxiv.org/abs/2409.18807},
	doi = {10.48550/arXiv.2409.18807},
	abstract = {The integration of tools in augmenting large language models presents a novel approach toward enhancing the efficiency and accuracy of these models in handling specific, complex tasks. This paper delves into the methodology,challenges, and developments in the realm of teaching LLMs to use external tools, thereby pushing the boundaries of their capabilities beyond pre-existing knowledge bases. We introduce a standardized paradigm for tool integration guided by a series of functions that map user instructions to actionable plans and their execution, emphasizing the significance of understanding user intent, tool selection, and dynamic plan adjustment. Our exploration reveals the various challenges encountered, such as tool invocation timing, selection accuracy, and the need for robust reasoning processes. In addressing these challenges, we investigate techniques within the context of fine-tuning and incontext learning paradigms, highlighting innovative approaches to ensure diversity, augment datasets, and improve generalization.Furthermore, we investigate a perspective on enabling LLMs to not only utilize but also autonomously create tools, which may redefine their role from mere tool users to tool creators. Finally,we reproduced Chameleon's results on ScienceQA and analyzed the code structure.},
	urldate = {2025-06-24},
	publisher = {arXiv},
	author = {Shen, Zhuocheng},
	month = sep,
	year = {2024},
	note = {arXiv:2409.18807 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	annote = {Comment: 10 pages},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/HLQU339L/Shen - 2024 - LLM With Tools A Survey.pdf:application/pdf;Snapshot:/Users/terrytong/Zotero/storage/HXZXL6HU/2409.html:text/html},
}


%codepapers


@inproceedings{karmakar_what_2021,
	title = {What do pre-trained code models know about code?},
	url = {https://ieeexplore.ieee.org/document/9678927/},
	doi = {10.1109/ASE51524.2021.9678927},
	abstract = {Pre-trained models of code built on the transformer architecture have performed well on software engineering (SE) tasks such as predictive code generation, code summarization, among others. However, whether the vector representations from these pre-trained models comprehensively encode characteristics of source code well enough to be applicable to a broad spectrum of downstream tasks remains an open question.One way to investigate this is with diagnostic tasks called probes. In this paper, we construct four probing tasks (probing for surface-level, syntactic, structural, and semantic information) for pre-trained code models. We show how probes can be used to identify whether models are deficient in (understanding) certain code properties, characterize different model layers, and get insight into the model sample-efficiency.We probe four models that vary in their expected knowledge of code properties: BERT (pre-trained on English), CodeBERT and CodeBERTa (pre-trained on source code, and natural language documentation), and GraphCodeBERT (pre-trained on source code with dataflow). While GraphCodeBERT performs more consistently overall, we find that BERT performs surprisingly well on some code tasks, which calls for further investigation.},
	urldate = {2025-08-28},
	booktitle = {2021 36th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering} ({ASE})},
	author = {Karmakar, Anjan and Robbes, Romain},
	month = nov,
	year = {2021},
	note = {ISSN: 2643-1572},
	keywords = {Predictive models, Natural languages, Bit error rate, Codes, probing, Semantics, software engineering tasks, source code models, Syntactics, transformers, Transformers},
	pages = {1332--1336},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/Z2VG46DT/Karmakar and Robbes - 2021 - What do pre-trained code models know about code.pdf:application/pdf},
}


@inproceedings{wan_what_2022,
	address = {Pittsburgh Pennsylvania},
	title = {What do they capture?: a structural analysis of pre-trained language models for source code},
	isbn = {978-1-4503-9221-1},
	shorttitle = {What do they capture?},
	url = {https://dl.acm.org/doi/10.1145/3510003.3510050},
	doi = {10.1145/3510003.3510050},
	language = {en},
	urldate = {2025-08-28},
	booktitle = {Proceedings of the 44th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Wan, Yao and Zhao, Wei and Zhang, Hongyu and Sui, Yulei and Xu, Guandong and Jin, Hai},
	month = may,
	year = {2022},
	pages = {2377--2388},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/JNDZ2K93/Wan et al. - 2022 - What do they capture a structural analysis of pre-trained language models for source code.pdf:application/pdf},
}



@inproceedings{troshin_probing_2022,
	address = {Abu Dhabi, United Arab Emirates (Hybrid)},
	title = {Probing {Pretrained} {Models} of {Source} {Codes}},
	url = {https://aclanthology.org/2022.blackboxnlp-1.31},
	doi = {10.18653/v1/2022.blackboxnlp-1.31},
	abstract = {Deep learning models are widely used for solving challenging code processing tasks, such as code generation or code summarization. Traditionally, a specific model architecture was carefully built to solve a particular code processing task. However, recently general pretrained models such as CodeBERT or CodeT5 have been shown to outperform task-specific models in many applications. While pretrained models are known to learn complex patterns from data, they may fail to understand some properties of source code. To test diverse aspects of code understanding, we introduce a set of diagnostic probing tasks. We show that pretrained models of code indeed contain information about code syntactic structure, the notions of identifiers, and namespaces, but they may fail to recognize more complex code properties such as semantic equivalence. We also investigate how probing results are affected by using code-specific pretraining objectives, varying the model size, or finetuning.},
	language = {en},
	urldate = {2025-08-28},
	booktitle = {Proceedings of the {Fifth} {BlackboxNLP} {Workshop} on {Analyzing} and {Interpreting} {Neural} {Networks} for {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Troshin, Sergey and Chirkova, Nadezhda},
	year = {2022},
	pages = {371--383},
	file = {PDF:/Users/terrytong/Zotero/storage/HPI7DZ6Q/Troshin and Chirkova - 2022 - Probing Pretrained Models of Source Codes.pdf:application/pdf},
}


@inproceedings{chen_neural_2018,
	address = {Montpellier France},
	title = {A neural framework for retrieval and summarization of source code},
	isbn = {978-1-4503-5937-5},
	url = {https://dl.acm.org/doi/10.1145/3238147.3240471},
	doi = {10.1145/3238147.3240471},
	language = {en},
	urldate = {2025-08-28},
	booktitle = {Proceedings of the 33rd {ACM}/{IEEE} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {ACM},
	author = {Chen, Qingying and Zhou, Minghui},
	month = sep,
	year = {2018},
	pages = {826--831},
	file = {Full Text PDF:/Users/terrytong/Zotero/storage/9TETZGJG/Chen and Zhou - 2018 - A neural framework for retrieval and summarization of source code.pdf:application/pdf},
}


@article{alon_code2vec_2019,
	title = {code2vec: learning distributed representations of code},
	volume = {3},
	issn = {2475-1421},
	shorttitle = {code2vec},
	url = {https://dl.acm.org/doi/10.1145/3290353},
	doi = {10.1145/3290353},
	abstract = {We present a neural model for representing snippets of code as continuous distributed vectors (``code embeddings''). The main idea is to represent a code snippet as a single fixed-length code vector, which can be used to predict semantic properties of the snippet. To this end, code is first decomposed to a collection of paths in its abstract syntax tree. Then, the network learns the atomic representation of each path while simultaneously learning how to aggregate a set of them.
            We demonstrate the effectiveness of our approach by using it to predict a method's name from the vector representation of its body. We evaluate our approach by training a model on a dataset of 12M methods. We show that code vectors trained on this dataset can predict method names from files that were unobserved during training. Furthermore, we show that our model learns useful method name vectors that capture semantic similarities, combinations, and analogies.
            A comparison of our approach to previous techniques over the same dataset shows an improvement of more than 75\%, making it the first to successfully predict method names based on a large, cross-project corpus. Our trained model, visualizations and vector similarities are available as an interactive online demo at http://code2vec.org. The code, data and trained models are available at https://github.com/tech-srl/code2vec.},
	language = {en},
	number = {POPL},
	urldate = {2025-08-28},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Alon, Uri and Zilberstein, Meital and Levy, Omer and Yahav, Eran},
	month = jan,
	year = {2019},
	pages = {1--29},
	file = {PDF:/Users/terrytong/Zotero/storage/W835BZHU/Alon et al. - 2019 - code2vec learning distributed representations of code.pdf:application/pdf},
}

@misc{puri_codenet_2021,
	title = {{CodeNet}: {A} {Large}-{Scale} {AI} for {Code} {Dataset} for {Learning} a {Diversity} of {Coding} {Tasks}},
	shorttitle = {{CodeNet}},
	url = {http://arxiv.org/abs/2105.12655},
	doi = {10.48550/arXiv.2105.12655},
	abstract = {Over the last several decades, software has been woven into the fabric of every aspect of our society. As software development surges and code infrastructure of enterprise applications ages, it is now more critical than ever to increase software development productivity and modernize legacy applications. Advances in deep learning and machine learning algorithms have enabled breakthroughs in computer vision, speech recognition, natural language processing and beyond, motivating researchers to leverage AI techniques to improve software development efﬁciency. Thus, the fast-emerging research area of “AI for Code” has garnered new interest and gathered momentum. In this paper, we present a large-scale dataset CodeNet, consisting of over 14 million code samples and about 500 million lines of code in 55 different programming languages, which is aimed at teaching AI to code. In addition to its large scale, CodeNet has a rich set of high-quality annotations to benchmark and help accelerate research in AI techniques for a variety of critical coding tasks, including code similarity and classiﬁcation, code translation between a large variety of programming languages, and code performance (runtime and memory) improvement techniques. Additionally, CodeNet provides sample input and output test sets for 98.5\% of the code samples, which can be used as an oracle for determining code correctness and potentially guide reinforcement learning for code quality improvements. As a usability feature, we provide several pre-processing tools in CodeNet to transform source code into representations that can be readily used as inputs into machine learning models. Results of code classiﬁcation and code similarity experiments using the CodeNet dataset are provided as a reference. We hope that the scale, diversity and rich, high-quality annotations of CodeNet will offer unprecedented research opportunities at the intersection of AI and Software Engineering.},
	language = {en},
	urldate = {2025-08-28},
	publisher = {arXiv},
	author = {Puri, Ruchir and Kung, David S. and Janssen, Geert and Zhang, Wei and Domeniconi, Giacomo and Zolotov, Vladimir and Dolby, Julian and Chen, Jie and Choudhury, Mihir and Decker, Lindsey and Thost, Veronika and Buratti, Luca and Pujar, Saurabh and Ramji, Shyam and Finkler, Ulrich and Malaika, Susan and Reiss, Frederick},
	month = aug,
	year = {2021},
	note = {arXiv:2105.12655 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Software Engineering},
	annote = {Comment: 22 pages including references},
	file = {PDF:/Users/terrytong/Zotero/storage/TVQ9YBDG/Puri et al. - 2021 - CodeNet A Large-Scale AI for Code Dataset for Learning a Diversity of Coding Tasks.pdf:application/pdf},
}

@article{blackwell1953equivalent,
  title={Equivalent Comparisons of Experiments},
  author={Blackwell, David},
  journal={The Annals of Mathematical Statistics},
  volume={24},
  number={2},
  pages={265--272},
  year={1953},
  publisher={Institute of Mathematical Statistics}
}
